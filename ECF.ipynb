{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import required libraries and scripts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:04:14] Initializing Normalizer\n",
      "/home/tony/.conda/envs/dockm8/lib/python3.8/site-packages/Bio/pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n",
      "/home/tony/.conda/envs/dockm8/lib/python3.8/site-packages/MDAnalysis/coordinates/chemfiles.py:108: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  MIN_CHEMFILES_VERSION = LooseVersion(\"0.9\")\n",
      "[TRJ.py:171 - <module>()] netCDF4 is not available. Writing AMBER ncdf files will be slow.\n",
      "/home/tony/.conda/envs/dockm8/lib/python3.8/site-packages/MDAnalysis/coordinates/TRJ.py:1209: DeprecationWarning: Please use `netcdf_file` from the `scipy.io` namespace, the `scipy.io.netcdf` namespace is deprecated.\n",
      "  class NCDFPicklable(scipy.io.netcdf.netcdf_file):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The working directory has been set to: /home/tony/Downloads/ECF/47mol\n",
      "The folder: /home/tony/Downloads/ECF/47mol/temp already exists\n"
     ]
    }
   ],
   "source": [
    "#Import required libraries and scripts\n",
    "from scripts.library_preparation import *\n",
    "from scripts.utilities import *\n",
    "from scripts.docking_functions import *\n",
    "from scripts.clustering_functions import *\n",
    "from scripts.rescoring_functions import *\n",
    "from scripts.consensus_methods import *\n",
    "from scripts.performance_calculation import *\n",
    "from scripts.dogsitescorer import *\n",
    "from scripts.get_pocket import *\n",
    "\n",
    "software = '/home/tony/DockM8/software'\n",
    "protein_file = '/home/tony/Downloads/ECF/47mol/ecfpanthit1_protoss.pdb'\n",
    "ref_file = '/home/tony/Downloads/ECF/47mol/ref_ligand.pdb'\n",
    "docking_library = '/home/tony/Downloads/ECF/47mol/IC50_mol_only.sdf'\n",
    "docking_programs = ['GNINA', 'SMINA', 'PLANTS']\n",
    "clustering_metrics = ['RMSD', 'spyRMSD', 'espsim', '3DScore', 'bestpose', 'bestpose_GNINA', 'bestpose_SMINA', 'bestpose_PLANTS']\n",
    "rescoring_functions = ['gnina', 'AD4', 'chemplp', 'rfscorevs', 'LinF9', 'RTMScore', 'SCORCH', 'vinardo']\n",
    "id_column = 'ID'\n",
    "n_poses = 10\n",
    "exhaustiveness = 8\n",
    "protonation = 'pkasolver'\n",
    "# ncpus = int(os.cpu_count()-2)\n",
    "ncpus = 7\n",
    "pocket = 'reference'\n",
    "#Create a temporary folder for all further calculations\n",
    "w_dir = os.path.dirname(protein_file)\n",
    "print('The working directory has been set to:', w_dir)\n",
    "create_temp_folder(w_dir+'/temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2023-Jun-06 15:04:17]: Extracting pocket from /home/tony/Downloads/ECF/47mol/ecfpanthit1_protoss.pdb using /home/tony/Downloads/ECF/47mol/ref_ligand.pdb as reference ligand\n",
      "\n",
      "[2023-Jun-06 15:04:17]: Radius of Gyration of reference ligand is: 4.132692647261068\n",
      "\n",
      "[2023-Jun-06 15:04:35]: Finished extracting pocket from /home/tony/Downloads/ECF/47mol/ecfpanthit1_protoss.pdb using /home/tony/Downloads/ECF/47mol/ref_ligand.pdb as reference ligand\n",
      "{'center': [67.84, 79.11, 89.67], 'size': [11.81, 11.81, 11.81]}\n"
     ]
    }
   ],
   "source": [
    "pocket = 'RoG'\n",
    "\n",
    "# if os.path.isfile(protein_file.replace('.pdb', '_pocket.pdb')) == False:\n",
    "if pocket == 'reference':\n",
    "    pocket_definition = get_pocket(ref_file, protein_file, 8)\n",
    "    print(pocket_definition)\n",
    "if pocket == 'RoG':\n",
    "    pocket_definition = get_pocket_RoG(ref_file, protein_file)\n",
    "    print(pocket_definition)\n",
    "elif pocket == 'dogsitescorer':\n",
    "    pocket_definition = binding_site_coordinates_dogsitescorer(protein_file, w_dir, method='volume')\n",
    "    print(pocket_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'center': [63.49, 76.77, 51.57], 'size': [31.64, 31.64, 31.64]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(w_dir+'/temp/final_library.sdf') == False:\n",
    "    prepare_library(docking_library, id_column, software, protonation, ncpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docking(w_dir, protein_file, ref_file, software, docking_programs, exhaustiveness, n_poses, ncpus, pocket_definition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading all poses SDF file...')\n",
    "tic = time.perf_counter()\n",
    "all_poses = PandasTools.LoadSDF(w_dir+'/temp/allposes.sdf', idName='Pose ID', molColName='Molecule', includeFingerprints=False, strictParsing=True)\n",
    "toc = time.perf_counter()\n",
    "print(f'Finished loading all poses SDF in {toc-tic:0.4f}!...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in clustering_metrics:\n",
    "        if os.path.isfile(w_dir+f'/temp/clustering/{metric}_clustered.sdf') == False:\n",
    "            cluster_pebble(metric, 'KMedoids', w_dir, protein_file, all_poses, ncpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in clustering_metrics:\n",
    "        rescore_all(w_dir, protein_file, ref_file, software, w_dir+f'/temp/clustering/{metric}_clustered.sdf', rescoring_functions, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates correlation to activity for each scoring function\n",
    "\n",
    "def calculate_EF_single_functions(w_dir, docking_library, clustering_metrics):\n",
    "    create_temp_folder(w_dir+'/temp/ranking')\n",
    "    rescoring_folders = {metric: f'rescoring_{metric}_clustered' for metric in clustering_metrics}\n",
    "    standardised_dataframes, ranked_dataframes = process_dataframes(w_dir, rescoring_folders)\n",
    "    for name, df_dict in {'standardised': standardised_dataframes, 'ranked': ranked_dataframes}.items():\n",
    "        for df_name, df in df_dict.items():\n",
    "            df['ID'] = df['Pose ID'].str.split('_').str[0]\n",
    "            df.to_csv(w_dir + f'/temp/ranking/{df_name}.csv', index=False)\n",
    "    \n",
    "    original_df = PandasTools.LoadSDF(docking_library, molColName='Molecule', idName='ID')\n",
    "    original_df = original_df[['ID', 'Activity']]\n",
    "    original_df['Activity'] = pd.to_numeric(original_df['Activity'])\n",
    "    results = pd.DataFrame(columns=['Scoring Function', 'Clustering Metric', 'Corr'])\n",
    "    #Calculate EFs for separate scoring functions\n",
    "    def calculate_correlation(col, df):\n",
    "        correlation, p_value = pearsonr(df[col], df['Activity'])\n",
    "        return correlation\n",
    "    for file in os.listdir(w_dir+'/temp/ranking'):\n",
    "        if file.endswith('_standardised.csv'):\n",
    "            clustering_metric = file.replace('_standardised.csv', '')\n",
    "            std_df = pd.read_csv(w_dir+'/temp/ranking/'+file)\n",
    "            numeric_cols = std_df.select_dtypes(include='number').columns\n",
    "            std_df_grouped = std_df.groupby('ID')[numeric_cols].mean().reset_index()\n",
    "            merged_df = pd.merge(std_df_grouped, original_df, on='ID')\n",
    "            for col in merged_df.columns:\n",
    "                if col not in ['ID', 'Activity']:\n",
    "                    corr = calculate_correlation (col, merged_df)\n",
    "                    results.loc[len(results)] = [col, clustering_metric, corr]\n",
    "    create_temp_folder(w_dir+'/temp/consensus')\n",
    "    results.to_csv(w_dir+'/temp/consensus/Corr_single_functions.csv')\n",
    "\n",
    "calculate_EF_single_functions(w_dir, '/home/tony/Downloads/ECF/47mol/IC50_mol_only_STD.sdf', clustering_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates correlation to activity for each consensus method and set of scoring function\n",
    "\n",
    "def process_combination(combination, w_dir, name, standardised_df, ranked_df, column_mapping, rank_methods, score_methods, docking_library, original_df):\n",
    "    selected_columns = list(combination)\n",
    "    ranked_selected_columns = [column_mapping[col] for col in selected_columns]\n",
    "    subset_name = '_'.join(selected_columns)\n",
    "    replacements_dict = {'_R_': '','_S_': '_'}\n",
    "    for key, value in replacements_dict.items():\n",
    "        subset_name = subset_name.replace(key, value)\n",
    "    standardised_subset = standardised_df[['ID'] + selected_columns]\n",
    "    ranked_subset = ranked_df[['ID'] + ranked_selected_columns]\n",
    "    analysed_dataframes = {method: rank_methods[method](ranked_subset, name, ranked_selected_columns) for method in rank_methods}\n",
    "    analysed_dataframes.update({method: score_methods[method](standardised_subset, name, selected_columns) for method in score_methods})\n",
    "    def calculate_EF1(df, w_dir, docking_library, original_df):\n",
    "        #Calculate EFs for consensus methods\n",
    "        merged_df = df.merge(original_df, on='ID')\n",
    "        method_list = df.columns.tolist()[1:]\n",
    "        method_ranking = {'ECR':False, 'Zscore':False, 'RbV':False, 'RbR':True}\n",
    "        for method in method_list:\n",
    "            asc = [method_ranking[key] for key in method_ranking if key in method][0]\n",
    "            sorted_df = merged_df.sort_values(method, ascending = asc)\n",
    "            N1_percent = round(0.01 * len(sorted_df))\n",
    "            N100_percent = len(sorted_df)\n",
    "            Hits1_percent = sorted_df.head(N1_percent)['Activity'].sum()\n",
    "            Hits100_percent = sorted_df['Activity'].sum()\n",
    "            ef1 = round((Hits1_percent/N1_percent)*(N100_percent/Hits100_percent),2)\n",
    "        return ef1\n",
    "    def calculate_correlation(df, original_df):\n",
    "        df = df.merge(original_df, on='ID')\n",
    "        score_columns = [col for col in df.columns if col not in ['ID', 'Activity']]\n",
    "        correlation, p_value = pearsonr(df[score_columns[0]], df['Activity'])\n",
    "        return correlation\n",
    "    result_dict = {}\n",
    "    for method, df in analysed_dataframes.items():\n",
    "        df = df.drop(columns=\"Pose ID\", errors='ignore')\n",
    "        correlation = calculate_correlation(df, original_df)\n",
    "        # Create a new dataframe with the method name, selected columns, and enrichment factor\n",
    "        ef_df = pd.DataFrame({\n",
    "            'clustering_method': [name],\n",
    "            'method_name': [method],\n",
    "            'selected_columns': [subset_name],\n",
    "            'corr': [correlation]\n",
    "        })\n",
    "\n",
    "        result_dict[method] = ef_df\n",
    "    return result_dict\n",
    "\n",
    "def process_combination_wrapper(args):\n",
    "    return process_combination(*args)\n",
    "\n",
    "def apply_consensus_methods_combinations(w_dir, docking_library, clustering_metrics):\n",
    "    create_temp_folder(w_dir+'/temp/ranking')\n",
    "    rescoring_folders = {metric: f'rescoring_{metric}_clustered' for metric in clustering_metrics}\n",
    "    standardised_dataframes, ranked_dataframes = process_dataframes(w_dir, rescoring_folders)\n",
    "    for name, df_dict in {'standardised': standardised_dataframes, 'ranked': ranked_dataframes}.items():\n",
    "        for df_name, df in df_dict.items():\n",
    "            df['ID'] = df['Pose ID'].str.split('_').str[0]\n",
    "            df.to_csv(w_dir + f'/temp/ranking/{df_name}.csv', index=False)\n",
    "    create_temp_folder(w_dir+'/temp/consensus')\n",
    "    rank_methods = {'method1':method1_ECR_best, 'method2':method2_ECR_average, 'method3':method3_avg_ECR, 'method4':method4_RbR}\n",
    "    score_methods = {'method5':method5_RbV, 'method6':method6_Zscore_best, 'method7':method7_Zscore_avg}\n",
    "    \n",
    "    original_df = PandasTools.LoadSDF('/home/tony/Downloads/ECF/47mol/IC50_mol_only_STD.sdf', molColName=None, idName='ID')\n",
    "    original_df = original_df[['ID', 'Activity']]\n",
    "    original_df['Activity'] = pd.to_numeric(original_df['Activity'])\n",
    "    df_list = []\n",
    "    printlog('Calculating consensus methods for every possible score combination...')\n",
    "    for name in tqdm(rescoring_folders, total=len(rescoring_folders)):\n",
    "        standardised_df = standardised_dataframes[name+'_standardised']\n",
    "        ranked_df = ranked_dataframes[name+'_ranked']\n",
    "        calc_columns = [col for col in standardised_df.columns if col not in ['Pose ID', 'ID']]\n",
    "        column_mapping = {col: f\"{col}_R\" for col in calc_columns}\n",
    "        ranked_df = ranked_df.rename(columns=column_mapping)\n",
    "        parallel = Parallel(n_jobs=int(os.cpu_count()/2), backend='multiprocessing')\n",
    "        for L in range(2, len(calc_columns)):\n",
    "            combinations = list(itertools.combinations(calc_columns, L))\n",
    "            args = [(subset, w_dir, name, standardised_df, ranked_df, column_mapping, rank_methods, score_methods, docking_library, original_df) for subset in combinations]\n",
    "            results = parallel(delayed(process_combination_wrapper)(arg) for arg in args)\n",
    "            for result_dict in results:\n",
    "                for method, df in result_dict.items():\n",
    "                    df_list.append(df)\n",
    "            consensus_summary = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Save the consensus_summary DataFrame to a single CSV file\n",
    "    consensus_summary = pd.concat(df_list, ignore_index=True)\n",
    "    display(consensus_summary.head())\n",
    "    consensus_summary.to_csv(w_dir + '/temp/consensus/consensus_summary.csv', index=False)\n",
    "    \n",
    "apply_consensus_methods_combinations(w_dir, '/home/tony/Downloads/ECF/47mol/IC50_mol_only_STD.sdf', clustering_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use if you want to output the scores for one consensus method\n",
    "\n",
    "def apply_consensus_methods(w_dir, clustering_metric, method, rescoring_functions):\n",
    "    create_temp_folder(w_dir+'/temp/ranking')\n",
    "    rescoring_folder = f'rescoring_{clustering_metric}_clustered'\n",
    "    rescored_dataframe = pd.read_csv(w_dir + f'/temp/{rescoring_folder}/allposes_rescored.csv')\n",
    "    standardised_dataframe = standardize_scores(rescored_dataframe)\n",
    "    col_dict = {\n",
    "    'gnina': 'GNINA_Affinity', 'cnn-score': 'CNN-Score', 'cnn-affinity': 'CNN-Affinity', \n",
    "    'vinardo': 'Vinardo', 'AD4': 'AD4', 'LinF9': 'LinF9', 'rfscorevs': 'RFScoreVS', \n",
    "    'plp': 'PLP', 'chemplp': 'CHEMPLP', 'NNScore': 'NNScore', 'PLECnn': 'PLECnn', \n",
    "    'AAScore': 'AAScore', 'ECIF': 'ECIF', 'SCORCH': 'SCORCH', 'RTMScore': 'RTMScore'\n",
    "    }\n",
    "    col_list = ['Pose ID'] + [col_dict[function] for function in rescoring_functions if function in col_dict]\n",
    "\n",
    "    filtered_dataframe = standardised_dataframe[col_list]\n",
    "    \n",
    "    print(filtered_dataframe)\n",
    "    #show_correlation(filtered_dataframe)\n",
    "    standardised_dataframes, ranked_dataframes = process_dataframes(w_dir, {clustering_metric: rescoring_folder})\n",
    "    for name, df_dict in {'standardised': standardised_dataframes, 'ranked': ranked_dataframes}.items():\n",
    "        for df_name, df in df_dict.items():\n",
    "            df['ID'] = df['Pose ID'].str.split('_').str[0]\n",
    "            df.to_csv(w_dir + f'/temp/ranking/{df_name}.csv', index=False)\n",
    "\n",
    "    create_temp_folder(w_dir+'/temp/consensus')\n",
    "    rank_methods = {'method1': method1_ECR_best, 'method2': method2_ECR_average, 'method3': method3_avg_ECR, 'method4': method4_RbR}\n",
    "    score_methods = {'method5': method5_RbV, 'method6': method6_Zscore_best, 'method7': method7_Zscore_avg}\n",
    "\n",
    "    if method in rank_methods:\n",
    "        method_function = rank_methods[method]\n",
    "        analysed_dataframe = method_function(ranked_dataframes[clustering_metric+'_ranked'], clustering_metric, [col for col in ranked_dataframes[clustering_metric+'_ranked'] if col not in ['Pose ID', 'ID']])\n",
    "    elif method in score_methods:\n",
    "        method_function = score_methods[method]\n",
    "        analysed_dataframe = method_function(standardised_dataframes[clustering_metric+'_standardised'], clustering_metric, [col for col in standardised_dataframes[clustering_metric+'_standardised'] if col not in ['Pose ID', 'ID']])\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid method: {method}\")\n",
    "\n",
    "    print(analysed_dataframe)\n",
    "    analysed_dataframe = analysed_dataframe.drop(columns=\"Pose ID\", errors='ignore')\n",
    "    analysed_dataframe.to_csv(w_dir+f'/temp/consensus/{clustering_metric}_{method}_results.csv', index=False)\n",
    "\n",
    "apply_consensus_methods(w_dir, 'bestpose_PLANTS', 'method6', ['SCORCH', 'AD4', 'RTMScore', 'gnina', 'cnn-affinity', 'rf-score-vs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "activity_df = PandasTools.LoadSDF('/home/tony/Downloads/ECF/47mol/IC50_mol_only_STD.sdf', idName='ID', molColName=None)\n",
    "consensus_df = pd.read_csv('/home/tony/Downloads/ECF/47mol/temp/consensus/bestpose_PLANTS_method6_results.csv')\n",
    "merged_df = pd.merge(activity_df, consensus_df, on='ID')\n",
    "merged_df.head()\n",
    "\n",
    "# Scatter plot\n",
    "plt.scatter(merged_df['Activity'], merged_df['Method6_Zscore_bestpose_PLANTS'], cmap='viridis')\n",
    "plt.colorbar(label='Activity')\n",
    "plt.xlabel('Activity')\n",
    "plt.ylabel('Method6_Zscore_bestpose_PLANTS')\n",
    "plt.title('Scatter Plot')\n",
    "plt.xticks(rotation=45)  # Rotating x-axis labels for better readability\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardise Activity using minmax\n",
    "\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import PandasTools\n",
    "\n",
    "# Load SDF file into a Pandas DataFrame\n",
    "sdf_file = '/home/tony/Downloads/ECF/47mol/IC50_mol_only.sdf'\n",
    "df = PandasTools.LoadSDF(sdf_file, idName='ID', molColName='Molecule')\n",
    "\n",
    "# Find the lowest original value in the 'Activity' column\n",
    "df['Activity'] = pd.to_numeric(df['Activity'])\n",
    "min_activity = df['Activity'].min()\n",
    "\n",
    "# Standardize and map 'Activity' column to a score between 0 and 1\n",
    "df['Activity'] = (df['Activity'] - min_activity) / (df['Activity'].max() - min_activity)\n",
    "\n",
    "# Sort the DataFrame by the 'Activity' column in descending order\n",
    "df = df.sort_values(by='Activity', ascending=False)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(df)\n",
    "PandasTools.WriteSDF(df, '/home/tony/Downloads/ECF/47mol/IC50_mol_only_STD.sdf', molColName='Molecule', idName='ID', properties=list(df.columns))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wocondock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10164e316682d9b4b376ca14144ea8a4ff51ebef10350aaa3c3bfce49f02faa4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
