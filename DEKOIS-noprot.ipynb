{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import required libraries and scripts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:20:53] Initializing Normalizer\n",
      "/home/alacournola/anaconda3/envs/dockm8/lib/python3.8/site-packages/MDAnalysis/coordinates/chemfiles.py:108: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  MIN_CHEMFILES_VERSION = LooseVersion(\"0.9\")\n",
      "[TRJ.py:171 - <module>()] netCDF4 is not available. Writing AMBER ncdf files will be slow.\n",
      "/home/alacournola/anaconda3/envs/dockm8/lib/python3.8/site-packages/MDAnalysis/coordinates/TRJ.py:1209: DeprecationWarning: Please use `netcdf_file` from the `scipy.io` namespace, the `scipy.io.netcdf` namespace is deprecated.\n",
      "  class NCDFPicklable(scipy.io.netcdf.netcdf_file):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from scripts.library_preparation import *\n",
    "from scripts.utilities import *\n",
    "from scripts.docking_functions import *\n",
    "from scripts.clustering_functions import *\n",
    "from scripts.rescoring_functions import *\n",
    "from scripts.performance_calculation import *\n",
    "from scripts.performance_calculation import *\n",
    "from scripts.dogsitescorer import *\n",
    "from scripts.get_pocket import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aldr\n",
      "The working directory has been set to: /home/alacournola/DEKOIS-noprot/aldr\n",
      "The folder: /home/alacournola/DEKOIS-noprot/aldr/temp already exists\n",
      "The folder: /home/alacournola/DEKOIS-noprot/aldr/temp/ranking already exists\n",
      "The folder: /home/alacournola/DEKOIS-noprot/aldr/temp/consensus already exists\n",
      "The folder: /home/alacournola/DEKOIS-noprot/aldr/temp/ranking already exists\n",
      "The folder: /home/alacournola/DEKOIS-noprot/aldr/temp/consensus already exists\n",
      "\n",
      "[2023-May-12 11:20:58]: Calculating consensus methods for every possible score combination...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [04:13<00:00, 31.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdac2\n",
      "The working directory has been set to: /home/alacournola/DEKOIS-noprot/hdac2\n",
      "The folder: /home/alacournola/DEKOIS-noprot/hdac2/temp already exists\n",
      "The folder: /home/alacournola/DEKOIS-noprot/hdac2/temp/ranking already exists\n",
      "The folder: /home/alacournola/DEKOIS-noprot/hdac2/temp/consensus was created\n",
      "The folder: /home/alacournola/DEKOIS-noprot/hdac2/temp/ranking already exists\n",
      "The folder: /home/alacournola/DEKOIS-noprot/hdac2/temp/consensus already exists\n",
      "\n",
      "[2023-May-12 11:25:20]: Calculating consensus methods for every possible score combination...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [04:14<00:00, 31.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdk2\n",
      "The working directory has been set to: /home/alacournola/DEKOIS-noprot/cdk2\n",
      "The folder: /home/alacournola/DEKOIS-noprot/cdk2/temp already exists\n",
      "The folder: /home/alacournola/DEKOIS-noprot/cdk2/temp/ranking already exists\n",
      "The folder: /home/alacournola/DEKOIS-noprot/cdk2/temp/consensus was created\n",
      "The folder: /home/alacournola/DEKOIS-noprot/cdk2/temp/ranking already exists\n",
      "The folder: /home/alacournola/DEKOIS-noprot/cdk2/temp/consensus already exists\n",
      "\n",
      "[2023-May-12 11:29:42]: Calculating consensus methods for every possible score combination...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [04:14<00:00, 31.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "igf1r\n",
      "The working directory has been set to: /home/alacournola/DEKOIS-noprot/igf1r\n",
      "The folder: /home/alacournola/DEKOIS-noprot/igf1r/temp already exists\n",
      "The folder: /home/alacournola/DEKOIS-noprot/igf1r/temp/ranking already exists\n",
      "The folder: /home/alacournola/DEKOIS-noprot/igf1r/temp/consensus was created\n",
      "The folder: /home/alacournola/DEKOIS-noprot/igf1r/temp/ranking already exists\n",
      "The folder: /home/alacournola/DEKOIS-noprot/igf1r/temp/consensus already exists\n",
      "\n",
      "[2023-May-12 11:34:03]: Calculating consensus methods for every possible score combination...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [04:19<00:00, 32.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nram\n",
      "The working directory has been set to: /home/alacournola/DEKOIS-noprot/nram\n",
      "The folder: /home/alacournola/DEKOIS-noprot/nram/temp already exists\n",
      "The folder: /home/alacournola/DEKOIS-noprot/nram/temp/ranking already exists\n",
      "The folder: /home/alacournola/DEKOIS-noprot/nram/temp/consensus was created\n",
      "The folder: /home/alacournola/DEKOIS-noprot/nram/temp/ranking already exists\n",
      "The folder: /home/alacournola/DEKOIS-noprot/nram/temp/consensus already exists\n",
      "\n",
      "[2023-May-12 11:38:31]: Calculating consensus methods for every possible score combination...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [04:12<00:00, 31.51s/it]\n"
     ]
    }
   ],
   "source": [
    "for dir in os.listdir('/home/alacournola/DEKOIS-noprot/'):\n",
    "    print(dir)\n",
    "    software = '/home/alacournola/DockM8/software'\n",
    "    protein_file = f'/home/alacournola/DEKOIS-noprot/{dir}/receptor_protoss_prepared.pdb'\n",
    "    ref_file = f'/home/alacournola/DEKOIS-noprot/{dir}/crystal_ligand_protoss.sdf'\n",
    "    pocket = 'reference'\n",
    "    protonation = 'none'\n",
    "    docking_library = f'/home/alacournola/DEKOIS-noprot/{dir}/merged_actives_decoys.sdf'\n",
    "    docking_programs = ['GNINA', 'SMINA', 'PLANTS']\n",
    "    clustering_metrics = ['RMSD', 'spyRMSD', 'espsim', '3DScore', 'bestpose', 'bestpose_GNINA', 'bestpose_SMINA', 'bestpose_PLANTS']\n",
    "    clustering_method = 'KMedoids'\n",
    "    rescoring= ['gnina', 'AD4', 'chemplp', 'rfscorevs', 'LinF9', 'SCORCH', 'RTMScore', 'vinardo']\n",
    "    id_column = 'ID'\n",
    "    n_poses = 10\n",
    "    exhaustiveness = 8\n",
    "    #ncpus = 1\n",
    "    ncpus = int(os.cpu_count()-2)\n",
    "    #Create a temporary folder for all further calculations\n",
    "    w_dir = os.path.dirname(protein_file)\n",
    "    print('The working directory has been set to:', w_dir)\n",
    "    create_temp_folder(w_dir+'/temp')\n",
    "    \n",
    "    try:\n",
    "        calculate_EF_single_functions(w_dir, docking_library, clustering_metrics)\n",
    "        apply_consensus_methods_combinations(w_dir, docking_library, clustering_metrics)\n",
    "    except Exception as e:\n",
    "        printlog(f'Failed for {dir}')\n",
    "        print(e)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns_in_csv(root_dir, target_file, col_rename_dict):\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if target_file in filename:\n",
    "                filepath = os.path.join(dirpath, filename)\n",
    "                df = pd.read_csv(filepath)\n",
    "                df.rename(columns=col_rename_dict, inplace=True)\n",
    "                df.to_csv(filepath, index=False)\n",
    "                print(f\"Columns renamed in: {filepath}\")\n",
    "\n",
    "root_directory = \"/media/mario/T7/FINISHED/FINISHED/\"\n",
    "target_csv_file = \"allposes_rescored.csv\"\n",
    "column_rename_dict = {\n",
    "    \"AD4_Affinity\": \"AD4\",\n",
    "    \"Vinardo_Affinity\": \"Vinardo\",\n",
    "    \"GNINA_Affinity\": \"GNINA\",\n",
    "    \"GNINA_CNN_Score\": \"CNN-Score\",\n",
    "    \"GNINA_CNN_Affinity\": \"CNN-Affinity\",\n",
    "    'LinF9_Affinity':'LinF9',\n",
    "    'SCORCH_pose_score':'SCORCH',\n",
    "    # Add more column names to be renamed here\n",
    "}\n",
    "rename_columns_in_csv(root_directory, target_csv_file, column_rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def rename_and_merge_csv_files(root_dir, target_file, output_file):\n",
    "    merged_df = None\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if filename == target_file:\n",
    "                filepath = os.path.join(dirpath, filename)\n",
    "                df = pd.read_csv(filepath, index_col=0)\n",
    "                dirname = os.path.basename(dirpath)\n",
    "                print(dirpath.replace('/media/mario/T7/FINISHED/FINISHED/', '').replace('/temp/consensus', ''))\n",
    "                df.rename(columns={\"EF1%\": dirpath.replace('/media/mario/T7/FINISHED/FINISHED/', '').replace('/temp/consensus', '')}, inplace=True)\n",
    "                df.drop(columns='EF10%', inplace=True)\n",
    "                if merged_df is None:\n",
    "                    merged_df = df\n",
    "                else:\n",
    "                    merged_df = pd.merge(merged_df, df, on=[\"Scoring Function\", \"Clustering Metric\"])\n",
    "\n",
    "    if merged_df is not None:\n",
    "        # Adding the average column\n",
    "        columns_to_exclude = ['method_name', 'selected_columns', 'clustering_metric']\n",
    "        numeric_columns = [col for col in merged_df.columns if col not in columns_to_exclude]\n",
    "        merged_df['Average'] = merged_df[numeric_columns].mean(axis=1)\n",
    "        merged_df.to_csv(output_file)\n",
    "        print(f\"Merged CSV file saved to: {output_file}\")\n",
    "\n",
    "\n",
    "root_directory = \"/media/mario/T7/FINISHED/FINISHED/\"\n",
    "target_csv_file = \"EF_single_functions.csv\"\n",
    "output_csv_file = \"merged_output_DUD-E.csv\"\n",
    "\n",
    "rename_and_merge_csv_files(root_directory, target_csv_file, output_csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def rename_and_merge_csv_files(root_dir, target_file, output_file):\n",
    "    merged_df = None\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if filename == target_file:\n",
    "                filepath = os.path.join(dirpath, filename)\n",
    "                df = pd.read_csv(filepath, index_col=0)\n",
    "                dirname = os.path.basename(dirpath)\n",
    "                df.rename(columns={\"EF1%\": dirpath.replace('/media/mario/T7/FINISHED/FINISHED/', '').replace('/temp/consensus', '')}, inplace=True)\n",
    "                if merged_df is None:\n",
    "                    merged_df = df\n",
    "                else:\n",
    "                    merged_df = pd.merge(merged_df, df, on=[\"clustering_method\", \"selected_columns\", 'method_name'])\n",
    "                    print(merged_df.head())\n",
    "\n",
    "    if merged_df is not None:\n",
    "        # Adding the average column\n",
    "        columns_to_exclude = ['method_name', 'selected_columns', 'clustering_metric']\n",
    "        numeric_columns = [col for col in merged_df.columns if col not in columns_to_exclude]\n",
    "        merged_df['Average'] = merged_df[numeric_columns].mean(axis=1)\n",
    "        print(merged_df.head())\n",
    "        merged_df.to_csv(output_file)\n",
    "        print(f\"Merged CSV file saved to: {output_file}\")\n",
    "\n",
    "root_directory = \"/media/mario/T7/FINISHED/FINISHED/\"\n",
    "target_csv_file = \"consensus_summary.csv\"\n",
    "output_csv_file = \"merged_output_consensus_DUD-E.csv\"\n",
    "\n",
    "rename_and_merge_csv_files(root_directory, target_csv_file, output_csv_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wocondock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10164e316682d9b4b376ca14144ea8a4ff51ebef10350aaa3c3bfce49f02faa4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
