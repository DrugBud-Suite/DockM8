{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import required libraries and scripts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dir in os.listdir('/media/mario/T7/DEKOIS/'):\n",
    "    print(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scripts.library_preparation import *\n",
    "from scripts.utilities import *\n",
    "from scripts.docking_functions import *\n",
    "from scripts.clustering_functions import *\n",
    "from scripts.rescoring_functions import *\n",
    "from scripts.performance_calculation import *\n",
    "from scripts.performance_calculation import *\n",
    "from scripts.dogsitescorer import *\n",
    "from scripts.get_pocket import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in os.listdir('/media/mario/T7/DEKOIS/'):\n",
    "    print(dir)\n",
    "    software = '/home/mario/DockM8/software'\n",
    "    protein_file = f'/media/mario/T7/DEKOIS/{dir}/receptor_protoss_prepared.pdb'\n",
    "    ref_file = f'/media/mario/T7/DEKOIS/{dir}/crystal_ligand_protoss.sdf'\n",
    "    pocket = 'reference'\n",
    "    protonation = 'pkasolver'\n",
    "    docking_library = f'/media/mario/T7/DEKOIS/{dir}/merged_actives_decoys.sdf'\n",
    "    docking_programs = ['GNINA', 'SMINA', 'PLANTS']\n",
    "    clustering_metrics = ['RMSD', 'spyRMSD', 'espsim', '3DScore', 'bestpose', 'bestpose_GNINA', 'bestpose_SMINA', 'bestpose_PLANTS']\n",
    "    clustering_method = 'KMedoids'\n",
    "    rescoring= ['gnina', 'AD4', 'chemplp', 'rfscorevs', 'LinF9', 'SCORCH', 'RTMScore', 'vinardo']\n",
    "    id_column = 'ID'\n",
    "    n_poses = 10\n",
    "    exhaustiveness = 8\n",
    "    parallel = 1\n",
    "    ncpus = int(os.cpu_count()/2)\n",
    "    #Create a temporary folder for all further calculations\n",
    "    w_dir = os.path.dirname(protein_file)\n",
    "    print('The working directory has been set to:', w_dir)\n",
    "    create_temp_folder(w_dir+'/temp')\n",
    "    \n",
    "    #try:   \n",
    "    for metric in clustering_metrics:\n",
    "        rescore_all(w_dir, protein_file, ref_file, software, w_dir+f'/temp/clustering/{metric}_clustered.sdf', rescoring, ncpus)\n",
    "    calculate_EF_single_functions(w_dir, docking_library, clustering_metrics)\n",
    "    apply_consensus_methods_combinations(w_dir, docking_library, clustering_metrics)\n",
    "    #except Exception as e:\n",
    "    #    print ('failed for '+dir)\n",
    "    #    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns_in_csv(root_dir, target_file, col_rename_dict):\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if target_file in filename:\n",
    "                filepath = os.path.join(dirpath, filename)\n",
    "                df = pd.read_csv(filepath)\n",
    "                df.rename(columns=col_rename_dict, inplace=True)\n",
    "                df.to_csv(filepath, index=False)\n",
    "                print(f\"Columns renamed in: {filepath}\")\n",
    "\n",
    "root_directory = \"/media/mario/T7/DEKOIS/\"\n",
    "target_csv_file = \"scores.csv\"\n",
    "column_rename_dict = {\n",
    "    \"AD4_Affinity\": \"AD4\",\n",
    "    \"Vinardo_Affinity\": \"Vinardo\",\n",
    "    \"GNINA_Affinity\": \"GNINA\",\n",
    "    \"GNINA_CNN_Score\": \"CNN-Score\",\n",
    "    \"GNINA_CNN_Affinity\": \"CNN-Affinity\",\n",
    "    'LinF9_Affinity':'LinF9',\n",
    "    'SCORCH_pose_score':'SCORCH',\n",
    "    # Add more column names to be renamed here\n",
    "}\n",
    "rename_columns_in_csv(root_directory, target_csv_file, column_rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns_in_csv(root_dir, target_file, col_rename_dict):\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if filename == target_file:\n",
    "                filepath = os.path.join(dirpath, filename)\n",
    "\n",
    "                # Read the CSV file\n",
    "                df = pd.read_csv(filepath)\n",
    "\n",
    "                # Rename columns according to the dictionary\n",
    "                df.rename(columns=col_rename_dict, inplace=True)\n",
    "\n",
    "                # Write the modified CSV file back to the same location\n",
    "                df.to_csv(filepath, index=False)\n",
    "                print(f\"Columns renamed in: {filepath}\")\n",
    "\n",
    "root_directory = \"/media/mario/T7/DEKOIS/\"\n",
    "target_csv_file = \"allposes_rescored.csv\"\n",
    "column_rename_dict = {\n",
    "    \"AD4_Affinity\": \"AD4\",\n",
    "    \"Vinardo_Affinity\": \"Vinardo\",\n",
    "    \"GNINA_Affinity\": \"GNINA\",\n",
    "    \"GNINA_CNN_Score\": \"CNN-Score\",\n",
    "    \"GNINA_CNN_Affinity\": \"CNN-Affinity\",\n",
    "    'LinF9_Affinity':'LinF9',\n",
    "    'SCORCH_pose_score':'SCORCH',\n",
    "    # Add more column names to be renamed here\n",
    "}\n",
    "rename_columns_in_csv(root_directory, target_csv_file, column_rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def rename_and_merge_csv_files(root_dir, target_file, output_file):\n",
    "    merged_df = None\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if filename == target_file:\n",
    "                filepath = os.path.join(dirpath, filename)\n",
    "                df = pd.read_csv(filepath, index_col=0)\n",
    "                dirname = os.path.basename(dirpath)\n",
    "                print(dirpath.replace('/media/mario/T7/DEKOIS/', '').replace('/temp/consensus', ''))\n",
    "                df.rename(columns={\"EF1%\": dirpath.replace('/media/mario/T7/DEKOIS/', '').replace('/temp/consensus', '')}, inplace=True)\n",
    "                df.drop(columns='EF10%', inplace=True)\n",
    "                if merged_df is None:\n",
    "                    merged_df = df\n",
    "                else:\n",
    "                    merged_df = pd.merge(merged_df, df, on=[\"Scoring Function\", \"Clustering Metric\"])\n",
    "\n",
    "    if merged_df is not None:\n",
    "        # Adding the average column\n",
    "        columns_to_exclude = ['method_name', 'selected_columns', 'clustering_metric']\n",
    "        numeric_columns = [col for col in merged_df.columns if col not in columns_to_exclude]\n",
    "        merged_df['Average'] = merged_df[numeric_columns].mean(axis=1)\n",
    "        merged_df.to_csv(output_file)\n",
    "        print(f\"Merged CSV file saved to: {output_file}\")\n",
    "\n",
    "\n",
    "root_directory = \"/media/mario/T7/DEKOIS/\"\n",
    "target_csv_file = \"EF_single_functions.csv\"\n",
    "output_csv_file = \"merged_output_DEKOIS.csv\"\n",
    "\n",
    "rename_and_merge_csv_files(root_directory, target_csv_file, output_csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dfs = []\n",
    "for dirpath, dirnames, filenames in os.walk(\"/media/mario/T7/DEKOIS/\"):\n",
    "        for filename in filenames:\n",
    "            if filename == \"consensus_summary.csv\":\n",
    "                filepath = os.path.join(dirpath, filename)\n",
    "                dirname = os.path.basename(dirpath)\n",
    "                column_name = dirpath.replace('/media/mario/T7/DEKOIS/', '').replace('/temp/consensus', '')\n",
    "\n",
    "                df = pd.read_csv(filepath, index_col=0)\n",
    "                df.rename(columns={\"EF1%\": column_name}, inplace=True)\n",
    "                print(df.head())\n",
    "                dfs.append(df)\n",
    "                \n",
    "if dfs:\n",
    "    merged_df = dfs[0]\n",
    "    for df in dfs[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, on=[\"clustering_method\", \"selected_columns\", 'method_name'])\n",
    "        print(merged_df.head())\n",
    "    # Adding the average column\n",
    "    columns_to_exclude = ['method_name', 'selected_columns', 'clustering_method']\n",
    "    numeric_columns = [col for col in merged_df.columns if col not in columns_to_exclude]\n",
    "    merged_df['Average'] = merged_df[numeric_columns].mean(axis=1)\n",
    "\n",
    "    print(merged_df.head())\n",
    "    merged_df.to_csv(\"merged_output_consensus_DEKOIS.csv\")\n",
    "    print(\"Merged CSV file saved to: merged_output_consensus_DEKOIS.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wocondock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10164e316682d9b4b376ca14144ea8a4ff51ebef10350aaa3c3bfce49f02faa4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
