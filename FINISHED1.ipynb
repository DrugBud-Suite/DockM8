{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import required libraries and scripts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scripts.library_preparation import *\n",
    "from scripts.utilities import *\n",
    "from scripts.docking_functions import *\n",
    "from scripts.clustering_functions import *\n",
    "from scripts.rescoring_functions import *\n",
    "from scripts.performance_calculation import *\n",
    "from scripts.dogsitescorer import *\n",
    "from scripts.get_pocket import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in tqdm(os.listdir('/home/alacournola/DUD-E')):\n",
    "    print(dir)\n",
    "    software = '/home/alacournola/DockM8/software'\n",
    "    protein_file = f'/home/alacournola/DUD-E/{dir}/receptor_protoss_prepared.pdb'\n",
    "    ref_file = f'/home/alacournola/DUD-E/{dir}/crystal_ligand_protoss.sdf'\n",
    "    pocket = 'reference'\n",
    "    protonation = 'pkasolver'\n",
    "    docking_library = f'/home/alacournola/DUD-E/{dir}/merged_actives_decoys.sdf'\n",
    "    docking_programs = ['GNINA', 'SMINA', 'PLANTS']\n",
    "    clustering_metrics = ['RMSD', 'spyRMSD', 'espsim', '3DScore', 'bestpose', 'bestpose_GNINA', 'bestpose_SMINA', 'bestpose_PLANTS']\n",
    "    clustering_method = 'KMedoids'\n",
    "    rescoring = ['gnina', 'AD4', 'chemplp', 'rfscorevs', 'LinF9', 'RTMScore', 'SCORCH', 'vinardo', 'KORPL', 'ConvexPLR']\n",
    "    id_column = 'ID'\n",
    "    n_poses = 10\n",
    "    exhaustiveness = 8\n",
    "    parallel = 1\n",
    "    ncpus = int(os.cpu_count()-2)\n",
    "    #Create a temporary folder for all further calculations\n",
    "    w_dir = Path(protein_file).parent\n",
    "    print('The working directory has been set to:', w_dir)\n",
    "    (w_dir/'temp').mkdir(exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        pocket_definition = get_pocket(ref_file, protein_file, 10)\n",
    "        for metric in clustering_metrics:\n",
    "            rescore_all(w_dir, protein_file, pocket_definition, str(w_dir / 'temp' / f'clustering/{metric}_clustered.sdf'), rescoring, ncpus)\n",
    "        if (w_dir/'temp'/'consensus').id_dir == False:\n",
    "            calculate_EF_single_functions(w_dir, docking_library, clustering_metrics)\n",
    "            apply_consensus_methods_combinations(w_dir, docking_library, clustering_metrics)\n",
    "    except Exception as e:\n",
    "        printlog(f'Failed for {dir}')\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "software = '/home/alacournola/DockM8/software'\n",
    "protein_file = f'/home/alacournola/DUD-E/xiap/receptor_protoss_prepared.pdb'\n",
    "ref_file = f'/home/alacournola/DUD-E/xiap/crystal_ligand_protoss.sdf'\n",
    "pocket = 'reference'\n",
    "protonation = 'pkasolver'\n",
    "docking_library = f'/home/alacournola/DUD-E/xiap/merged_actives_decoys.sdf'\n",
    "docking_programs = ['GNINA', 'SMINA', 'PLANTS']\n",
    "clustering_metrics = ['RMSD', 'spyRMSD', 'espsim', '3DScore', 'bestpose', 'bestpose_GNINA', 'bestpose_SMINA', 'bestpose_PLANTS']\n",
    "clustering_method = 'KMedoids'\n",
    "rescoring = ['gnina', 'AD4', 'chemplp', 'rfscorevs', 'LinF9', 'RTMScore', 'SCORCH', 'vinardo', 'KORPL', 'ConvexPLR']\n",
    "id_column = 'ID'\n",
    "n_poses = 10\n",
    "exhaustiveness = 8\n",
    "parallel = 1\n",
    "ncpus = int(os.cpu_count()-2)\n",
    "#Create a temporary folder for all further calculations\n",
    "w_dir = Path(protein_file).parent\n",
    "print('The working directory has been set to:', w_dir)\n",
    "(w_dir/'temp').mkdir(exist_ok=True)\n",
    "\n",
    "try:\n",
    "    pocket_definition = get_pocket(ref_file, protein_file, 10)\n",
    "    print('Loading all poses SDF file...')\n",
    "    tic = time.perf_counter()\n",
    "    all_poses = PandasTools.LoadSDF(str(w_dir / 'temp' / 'allposes.sdf'), idName='Pose ID', molColName='Molecule', includeFingerprints=False, strictParsing=True)\n",
    "    toc = time.perf_counter()\n",
    "    print(f'Finished loading all poses SDF in {toc-tic:0.4f}!...')\n",
    "    for metric in clustering_metrics:\n",
    "        if os.path.isfile(w_dir / 'temp' / f'clustering/{metric}_clustered.sdf') == False:\n",
    "            cluster_pebble(metric, 'KMedoids', w_dir, protein_file, all_poses, ncpus)\n",
    "    for metric in clustering_metrics:\n",
    "        rescore_all(w_dir, protein_file, pocket_definition, str(w_dir / 'temp' / f'clustering/{metric}_clustered.sdf'), rescoring, ncpus)\n",
    "    calculate_EF_single_functions(w_dir, docking_library, clustering_metrics)\n",
    "    apply_consensus_methods_combinations(w_dir, docking_library, clustering_metrics)\n",
    "except Exception as e:\n",
    "    printlog(f'Failed for xiap')\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def rename_and_merge_csv_files(root_dir, target_file, output_file):\n",
    "    merged_df = None\n",
    "\n",
    "    for dirpath, dirnames, filenames in tqdm(os.walk(root_dir)):\n",
    "        for filename in filenames:\n",
    "            if filename == target_file:\n",
    "                filepath = os.path.join(dirpath, filename)\n",
    "                df = pd.read_csv(filepath, index_col=0)\n",
    "                display(dirpath)\n",
    "                dirname = os.path.basename(dirpath)\n",
    "                df[\"EF1%\"] = pd.to_numeric(df[\"EF1%\"], errors='coerce')\n",
    "                df.rename(columns={\"EF1%\": dirpath.replace('/home/alacournola/DUD-E/', '').replace('/temp/consensus', '')}, inplace=True)\n",
    "                df.drop(columns='EF10%', inplace=True)\n",
    "                if merged_df is None:\n",
    "                    merged_df = df\n",
    "                else:\n",
    "                    merged_df = pd.merge(merged_df, df, on=[\"Scoring Function\", \"Clustering Metric\"])\n",
    "\n",
    "    if merged_df is not None:\n",
    "        # Adding the average column\n",
    "        columns_to_exclude = [\"Scoring Function\", \"Clustering Metric\"]\n",
    "        numeric_columns = [col for col in merged_df.columns if col not in columns_to_exclude]\n",
    "        merged_df['Average'] = merged_df[numeric_columns].mean(axis=1)\n",
    "        merged_df.to_csv(output_file)\n",
    "        print(f\"Merged CSV file saved to: {output_file}\")\n",
    "\n",
    "\n",
    "root_directory = \"/home/alacournola/DUD-E\"\n",
    "target_csv_file = \"EF_single_functions.csv\"\n",
    "output_csv_file = \"merged_output_DUD-E.csv\"\n",
    "\n",
    "rename_and_merge_csv_files(root_directory, target_csv_file, output_csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def rename_and_merge_csv_files(root_dir, target_file, output_file):\n",
    "    merged_df = None\n",
    "\n",
    "    for dirpath, dirnames, filenames in tqdm(os.walk(root_dir)):\n",
    "        for filename in filenames:\n",
    "            if filename == target_file:\n",
    "                filepath = os.path.join(dirpath, filename)\n",
    "                df = pd.read_csv(filepath, index_col=0)\n",
    "                dirname = os.path.basename(dirpath)\n",
    "                df.rename(columns={\"EF1%\": dirpath.replace('/home/alacournola/DUD/E/', '').replace('/temp/consensus', '')}, inplace=True)\n",
    "                if merged_df is None:\n",
    "                    merged_df = df\n",
    "                else:\n",
    "                    merged_df = pd.merge(merged_df, df, on=[\"clustering_method\", \"selected_columns\", 'method_name'])\n",
    "                    print(merged_df.head())\n",
    "\n",
    "    if merged_df is not None:\n",
    "        # Adding the average column\n",
    "        columns_to_exclude = ['method_name', 'selected_columns', 'clustering_metric']\n",
    "        numeric_columns = [col for col in merged_df.columns if col not in columns_to_exclude]\n",
    "        merged_df['Average'] = merged_df[numeric_columns].mean(axis=1)\n",
    "        print(merged_df.head())\n",
    "        merged_df.to_csv(output_file)\n",
    "        print(f\"Merged CSV file saved to: {output_file}\")\n",
    "\n",
    "root_directory = \"/home/alacournola/DUD-E\"\n",
    "target_csv_file = \"consensus_summary.csv\"\n",
    "output_csv_file = \"merged_output_consensus_DUD-E.csv\"\n",
    "\n",
    "rename_and_merge_csv_files(root_directory, target_csv_file, output_csv_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wocondock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10164e316682d9b4b376ca14144ea8a4ff51ebef10350aaa3c3bfce49f02faa4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
