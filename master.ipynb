{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import required librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem import rdFMCS\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Draw\n",
    "import chembl_structure_pipeline as pipeline\n",
    "from chembl_structure_pipeline import checker\n",
    "from chembl_structure_pipeline import standardizer\n",
    "import subprocess\n",
    "import shutil\n",
    "from pymol import cmd\n",
    "import pathlib\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from spyrmsd import io, rmsd\n",
    "from espsim import GetEspSim\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.cluster import KMeans, Birch, DBSCAN, SpectralClustering\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from kneed import KneeLocator\n",
    "from molvs import *\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Initial Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "software = '/media/drive/Software/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tony/Documents/consensus_docking_python\n"
     ]
    }
   ],
   "source": [
    "protein_file = '/home/tony/Documents/consensus_docking_python/2o1x_A_apo_protoss.pdb'\n",
    "ref_file = '/home/tony/Documents/consensus_docking_python/2o1x_A_lig_protoss.pdb'\n",
    "lig_file = '/home/tony/Documents/consensus_docking_python/Selection_of_FCHGroup_LeadLike.sdf'\n",
    "id_column = 'ID'\n",
    "n_poses = 10\n",
    "exhaustivness = 8\n",
    "\n",
    "#Initialise variables\n",
    "root_dir = os.path.dirname(protein_file)\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create temp folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create temporary folder for all subsequent work. Temp folder is created in folder containing .pdb file.\n",
    "def create_temp_folder():\n",
    "    if os.path.isdir(root_dir+'/temp') == True:\n",
    "        print('Temp folder already exists')\n",
    "    else:\n",
    "        os.mkdir(root_dir+'/temp')\n",
    "\n",
    "create_temp_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Clean library sdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_library(sdf):\n",
    "    #Load Library SDF into Pandas\n",
    "    try:\n",
    "        df = PandasTools.LoadSDF(lig_file, idName=id_column, molColName='Molecule',includeFingerprints=False, embedProps=True, removeHs=True, strictParsing=True, smilesName='SMILES')\n",
    "    except:\n",
    "        print('ERROR: Failed to Load library SDF file!')\n",
    "    #Standardize molecules using ChemBL Pipeline\n",
    "    df['Molecule'] = [standardizer.standardize_mol(mol) for mol in df['Molecule']]\n",
    "    df['Molecule'] = [standardizer.get_parent_mol(mol) for mol in df['Molecule']]\n",
    "    df[['Molecule', 'flag']]=pd.DataFrame(df['Molecule'].tolist(), index=df.index)\n",
    "    df=df.drop(columns='flag')\n",
    "    std_sdf = root_dir+'/standardized_sdf.sdf'\n",
    "    #Write standardized molecules to temporary SDF file\n",
    "    try:\n",
    "        rdkit.Chem.PandasTools.WriteSDF(df, std_sdf, molColName='Molecule', idName=id_column, properties=list(df.columns), allNumeric=True)\n",
    "    except:\n",
    "        print('ERROR: Failed to write standardized library SDF file!')\n",
    "    # Protonate and Generate 3D conformers using Gypsum-DL\n",
    "    gypsum_sdf = root_dir+'/gypsum_dl_success.sdf'\n",
    "    try:\n",
    "        gypsum_dl_command = 'python '+software+'/gypsum_dl-1.1.9/run_gypsum_dl.py -s '+std_sdf+' --job_manager multiprocessing -p -1 -m 1 -t 10 --min_ph 7 --max_ph 8 --pka_precision 0.5 --skip_enumerate_chiral_mol --skip_enumerate_double_bonds'\n",
    "        os.system(gypsum_dl_command)\n",
    "    except:\n",
    "        print('ERROR: Failed to generate protomers and conformers!')\n",
    "    #Load final library into Pandas and clean excess columns\n",
    "    cleaned_library_df = PandasTools.LoadSDF(gypsum_sdf, idName=id_column, molColName='Molecule',includeFingerprints=False, embedProps=False, removeHs=False, strictParsing=True)\n",
    "    cleaned_library_df = cleaned_library_df[['Molecule', id_column]]\n",
    "    cleaned_library_df = cleaned_library_df.iloc[1: , :]\n",
    "    #Write final library to SDF file\n",
    "    final_sdf = root_dir+'/final_library.sdf'\n",
    "    try:\n",
    "        rdkit.Chem.PandasTools.WriteSDF(cleaned_library_df, final_sdf, molColName='Molecule', idName=id_column)\n",
    "    except:\n",
    "        print('ERROR: Failed to write final library SDF file!')\n",
    "    #Remove temporary files\n",
    "    try:\n",
    "        os.remove(gypsum_sdf)\n",
    "        os.remove(gypsum_sdf.replace('_success.sdf', '_failed.smi'))\n",
    "    except:\n",
    "        print('ERROR: Could not remove gypsum files!')\n",
    "    try:\n",
    "        os.remove(root_dir+'/standardized_sdf.sdf')\n",
    "    except:\n",
    "        print('ERROR: Could not remove temporary sdf files!')\n",
    "    return cleaned_library_df\n",
    "\n",
    "cleaned_library_df = clean_library(lig_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. SMINA docking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smina_docking():\n",
    "    library = root_dir+'/final_library.sdf'\n",
    "    smina_folder = root_dir+'/temp/smina/'\n",
    "    try:\n",
    "        os.mkdir(smina_folder, mode = 0o777)\n",
    "    except:\n",
    "        print('Smina folder already exists')\n",
    "    results = smina_folder+'/docked.sdf'\n",
    "    log = smina_folder+'log.txt'\n",
    "    smina_cmd = 'gnina -r '+protein_file+' -l '+library+' --autobox_ligand '+ref_file+' -o '+results+' --exhaustiveness ' +str(exhaustivness)+' --num_modes '+str(n_poses)+' --cnn_scoring none'+' --log '+log\n",
    "    docker_cmd = 'sudo docker run --name smina --rm -v /home:/home gnina/gnina ' + smina_cmd\n",
    "    subprocess.call(docker_cmd, shell=True)\n",
    "    smina_poses = PandasTools.LoadSDF(results, idName=id_column, molColName='Molecule',includeFingerprints=False, embedProps=False, removeHs=False, strictParsing=True)\n",
    "    return smina_poses\n",
    "\n",
    "smina_poses = smina_docking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. GNINA docking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnina_docking():\n",
    "    library = root_dir+'/final_library.sdf'\n",
    "    gnina_folder = root_dir+'/temp/gnina/'\n",
    "    try:\n",
    "        os.mkdir(gnina_folder, mode = 0o777)\n",
    "    except:\n",
    "        print('Gnina folder already exists')\n",
    "    results = gnina_folder+'/docked.sdf'\n",
    "    log = gnina_folder+'log.txt'\n",
    "    gnina_cmd = 'gnina -r '+protein_file+' -l '+library+' --autobox_ligand '+ref_file+' -o '+results+' --exhaustiveness ' +str(exhaustivness)+' --num_modes '+str(n_poses)+' --cnn_scoring rescore --cnn crossdock_default2018 '+' --log '+log\n",
    "    docker_cmd = 'sudo docker run --name gnina --rm -v /home:/home gnina/gnina ' + gnina_cmd\n",
    "    subprocess.call(docker_cmd, shell=True)\n",
    "    gnina_poses = PandasTools.LoadSDF(results, idName=id_column, molColName='Molecule',includeFingerprints=False, embedProps=False, removeHs=False, strictParsing=True)\n",
    "    return gnina_poses\n",
    "\n",
    "gnina_poses = gnina_docking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. PLANTS docking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plants_search_speed = \"speed1\"\n",
    "ants = \"20\"\n",
    "plants_docking_scoring = \"chemplp\"\n",
    "plants_docking_dir = root_dir+\"/temp/plants\"\n",
    "plants_docking_results_dir = root_dir+\"/temp/plants/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders (title is /home/tony/Documents/consensus_docking_python/2o1x_A_apo_protoss.pdb)\n",
      "\n",
      "1 molecule converted\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders (title is /home/tony/Documents/consensus_docking_python/2o1x_A_lig_protoss.pdb)\n",
      "\n",
      "1 molecule converted\n",
      "10 molecules converted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                  PLANTS\n",
      "        Protein-Ligand ANT System\n",
      "               version 1.2\n",
      "\n",
      "\n",
      "author: Oliver Korb\n",
      "\n",
      "scientific contributors: T.E. Exner, T. Stuetzle\n",
      "\n",
      "contact: Oliver.Korb@uni-konstanz.de\n",
      "\n",
      "\n",
      "run PLANTS: PLANTS --mode screen yourconfigfile\n",
      "\n",
      "PLANTS info: CHO hydrogen found 188 HD2 HIS17\n",
      "PLANTS info: CHO hydrogen found 189 HE1 HIS17\n",
      "PLANTS info: CHO hydrogen found 736 HE1 HIS51\n",
      "PLANTS info: CHO hydrogen found 949 HD2 HIS66\n",
      "PLANTS info: CHO hydrogen found 950 HE1 HIS66\n",
      "PLANTS info: CHO hydrogen found 1212 HE1 HIS82\n",
      "PLANTS info: CHO hydrogen found 1755 HD2 HIS117\n",
      "PLANTS info: CHO hydrogen found 1756 HE1 HIS117\n",
      "PLANTS info: CHO hydrogen found 2177 HE1 HIS147\n",
      "PLANTS info: CHO hydrogen found 3177 HD2 HIS262\n",
      "PLANTS info: CHO hydrogen found 3178 HE1 HIS262\n",
      "PLANTS info: CHO hydrogen found 3858 HE1 HIS304\n",
      "PLANTS info: CHO hydrogen found 4713 HE1 HIS362\n",
      "PLANTS info: CHO hydrogen found 4744 HE1 HIS364\n",
      "PLANTS info: CHO hydrogen found 5423 HD2 HIS408\n",
      "PLANTS info: CHO hydrogen found 5424 HE1 HIS408\n",
      "PLANTS info: CHO hydrogen found 5512 HE1 HIS414\n",
      "PLANTS info: CHO hydrogen found 5790 HD2 HIS434\n",
      "PLANTS info: CHO hydrogen found 5791 HE1 HIS434\n",
      "PLANTS info: CHO hydrogen found 6358 HD2 HIS470\n",
      "PLANTS info: CHO hydrogen found 6359 HE1 HIS470\n",
      "PLANTS info: CHO hydrogen found 8034 HE1 HIS582\n",
      "PLANTS info: CHO hydrogen found 8273 HE1 HIS597\n",
      "WARNING: Metal atom as acceptor R-group! Acceptor: 2264 OD2 ASP154\n",
      "WARNING: Metal atom as acceptor R-group! Acceptor: 2677 OD1 ASN183\n",
      "PROTEIN METAL ATOM: 8705 MG\n",
      "virtual screening progress: 1 of 1\n",
      "current ligand: /home/tony/Documents/consensus_docking_python/temp/plants/ligands.mol2 (entry 1)\n",
      "LIGAND DOFs: 9\n",
      "PROTEIN DOFs: 15\n",
      "Simplex dimension: 24\n",
      "Simplex dimension: 24\n",
      "iterations : 200\n",
      "starting optimization ...\n",
      "problem dimension: 24\n",
      "ATOMS / s: 3.76198e+06\n",
      "EVAL / s: 268713\n",
      "optimization finished after 8.21s\n",
      "best score: -67.24\n",
      "\n",
      "\n",
      "current ligand: /home/tony/Documents/consensus_docking_python/temp/plants/ligands.mol2 (entry 2)\n",
      "LIGAND DOFs: 9\n",
      "PROTEIN DOFs: 15\n",
      "Simplex dimension: 24\n",
      "Simplex dimension: 24\n",
      "iterations : 228\n",
      "starting optimization ...\n",
      "problem dimension: 24\n",
      "ATOMS / s: 5470833.50\n",
      "EVAL / s: 237862.34\n",
      "optimization finished after 11.94s\n",
      "best score: -81.11\n",
      "\n",
      "\n",
      "current ligand: /home/tony/Documents/consensus_docking_python/temp/plants/ligands.mol2 (entry 3)\n",
      "LIGAND DOFs: 11\n",
      "PROTEIN DOFs: 15\n",
      "Simplex dimension: 26\n",
      "Simplex dimension: 26\n",
      "iterations : 275\n",
      "starting optimization ...\n",
      "problem dimension: 26\n",
      "ATOMS / s: 5315879.00\n",
      "EVAL / s: 295326.59\n",
      "optimization finished after 11.63s\n",
      "best score: -80.18\n",
      "\n",
      "\n",
      "current ligand: /home/tony/Documents/consensus_docking_python/temp/plants/ligands.mol2 (entry 4)\n",
      "LIGAND DOFs: 10\n",
      "PROTEIN DOFs: 15\n",
      "Simplex dimension: 25\n",
      "Simplex dimension: 25\n",
      "iterations : 262\n",
      "starting optimization ...\n",
      "problem dimension: 25\n",
      "ATOMS / s: 5368583.00\n",
      "EVAL / s: 223690.95\n",
      "optimization finished after 14.97s\n",
      "best score: -80.54\n",
      "\n",
      "\n",
      "current ligand: /home/tony/Documents/consensus_docking_python/temp/plants/ligands.mol2 (entry 5)\n",
      "LIGAND DOFs: 13\n",
      "PROTEIN DOFs: 15\n",
      "Simplex dimension: 28\n",
      "Simplex dimension: 28\n",
      "iterations : 362\n",
      "starting optimization ...\n",
      "problem dimension: 28\n",
      "ATOMS / s: 5364719.00\n",
      "EVAL / s: 206335.34\n",
      "optimization finished after 27.93s\n",
      "best score: -88.11\n",
      "\n",
      "\n",
      "current ligand: /home/tony/Documents/consensus_docking_python/temp/plants/ligands.mol2 (entry 6)\n",
      "LIGAND DOFs: 12\n",
      "PROTEIN DOFs: 15\n",
      "PLANTS info: CHO hydrogen found 39 H UNL1\n",
      "Simplex dimension: 27\n",
      "Simplex dimension: 27\n",
      "iterations : 337\n",
      "starting optimization ...\n",
      "problem dimension: 27\n",
      "ATOMS / s: 5599422.00\n",
      "EVAL / s: 199979.36\n",
      "optimization finished after 23.95s\n",
      "best score: -86.75\n",
      "\n",
      "\n",
      "current ligand: /home/tony/Documents/consensus_docking_python/temp/plants/ligands.mol2 (entry 7)\n",
      "LIGAND DOFs: 11\n",
      "PROTEIN DOFs: 15\n",
      "Simplex dimension: 26\n",
      "Simplex dimension: 26\n",
      "iterations : 296\n",
      "starting optimization ...\n",
      "problem dimension: 26\n",
      "ATOMS / s: 5212569.50\n",
      "EVAL / s: 208502.77\n",
      "optimization finished after 20.64s\n",
      "best score: -94.02\n",
      "\n",
      "\n",
      "current ligand: /home/tony/Documents/consensus_docking_python/temp/plants/ligands.mol2 (entry 8)\n",
      "LIGAND DOFs: 12\n",
      "PROTEIN DOFs: 15\n",
      "Simplex dimension: 27\n",
      "Simplex dimension: 27\n",
      "iterations : 315\n",
      "starting optimization ...\n",
      "problem dimension: 27\n",
      "ATOMS / s: 5085363.00\n",
      "EVAL / s: 242160.16\n",
      "optimization finished after 17.80s\n",
      "best score: -81.75\n",
      "\n",
      "\n",
      "current ligand: /home/tony/Documents/consensus_docking_python/temp/plants/ligands.mol2 (entry 9)\n",
      "LIGAND DOFs: 11\n",
      "PROTEIN DOFs: 15\n",
      "Simplex dimension: 26\n",
      "Simplex dimension: 26\n",
      "iterations : 278\n",
      "starting optimization ...\n",
      "problem dimension: 26\n",
      "ATOMS / s: 4514964.50\n",
      "EVAL / s: 237629.70\n",
      "optimization finished after 16.54s\n",
      "best score: -78.43\n",
      "\n",
      "\n",
      "current ligand: /home/tony/Documents/consensus_docking_python/temp/plants/ligands.mol2 (entry 10)\n",
      "LIGAND DOFs: 10\n",
      "PROTEIN DOFs: 15\n",
      "Simplex dimension: 25\n",
      "Simplex dimension: 25\n",
      "iterations : 262\n",
      "starting optimization ...\n",
      "problem dimension: 25\n",
      "ATOMS / s: 5902091.50\n",
      "EVAL / s: 245920.48\n",
      "optimization finished after 13.57s\n",
      "best score: -76.40\n",
      "\n",
      "\n",
      "total virtual screening time: 170.86s\n",
      "Ligands skipped due to errors: 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2850/960470905.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m \u001b[0mplants_docking_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinding_site_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinding_site_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinding_site_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinding_site_radius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplants_docking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "def plants_docking():\n",
    "    #Create plants docking folder\n",
    "    if os.path.isdir(plants_docking_dir) == True:\n",
    "        print('Plants docking folder already exists')\n",
    "    else:\n",
    "        os.mkdir(plants_docking_dir)\n",
    "    #Convert protein file to .mol2 using open babel\n",
    "    plants_protein_mol2 = root_dir+\"/temp/plants/protein.mol2\"\n",
    "    try:\n",
    "        obabel_command = 'obabel -ipdb '+protein_file+' -O '+plants_protein_mol2\n",
    "        os.system(obabel_command)\n",
    "    except:\n",
    "        print('ERROR: Failed to convert protein file to .mol2!')\n",
    "    #Convert protein file to .mol2 using open babel\n",
    "    plants_ref_mol2 = root_dir+\"/temp/plants/ref.mol2\"\n",
    "    if ref_file.endswith(\".mol2\"):\n",
    "        shutil.copy(ref_file, plants_docking_dir)\n",
    "        os.rename(plants_docking_dir+\"/\"+os.path.basename(ref_file), plants_ref_mol2)\n",
    "    if ref_file.endswith(\".sdf\"):\n",
    "        try:\n",
    "            obabel_command = 'obabel -isdf '+ref_file+' -O '+plants_ref_mol2\n",
    "            os.system(obabel_command)\n",
    "        except:\n",
    "            print('ERROR: Failed to convert reference ligand file to .mol2!')\n",
    "    if ref_file.endswith(\".pdb\"):\n",
    "        try:\n",
    "            obabel_command = 'obabel -ipdb '+ref_file+' -O '+plants_ref_mol2\n",
    "            os.system(obabel_command)\n",
    "        except:\n",
    "            print('ERROR: Failed to convert reference ligand file to .mol2!')\n",
    "    else:\n",
    "        print('ERROR: Reference ligand file not in a readable format!')\n",
    "    #Convert prepared ligand file to .mol2 using open babel\n",
    "    final_library = root_dir+\"/final_library.sdf\"\n",
    "    plants_ligands_mol2 = root_dir+\"/temp/plants/ligands.mol2\"\n",
    "    try:\n",
    "        obabel_command = 'obabel -isdf '+final_library+' -O '+plants_ligands_mol2\n",
    "        os.system(obabel_command)\n",
    "    except:\n",
    "        print('ERROR: Failed to convert library file to .mol2!')\n",
    "    #Determine binding site coordinates\n",
    "    plants_binding_site_command = \"cd \"+software+\" && ./PLANTS --mode bind \"+plants_ref_mol2+\" 6\"\n",
    "    run_plants_binding_site = os.popen(plants_binding_site_command)\n",
    "    output_plants_binding_site = run_plants_binding_site.readlines()\n",
    "    keep = []\n",
    "    for l in output_plants_binding_site:\n",
    "        if l.startswith(\"binding\"):\n",
    "            keep.append(l)\n",
    "        else:\n",
    "            pass\n",
    "    binding_site_center = keep[0].split()\n",
    "    binding_site_radius = keep[1].split()\n",
    "    binding_site_radius = binding_site_radius[1]\n",
    "    binding_site_x = binding_site_center[1]\n",
    "    binding_site_y = binding_site_center[2]\n",
    "    binding_site_z = binding_site_center[3]\n",
    "    #Generate plants config file\n",
    "    plants_docking_config_path_txt = plants_docking_dir+\"/config.txt\"\n",
    "    plants_config = ['# search algorithm\\n',\n",
    "    'search_speed '+plants_search_speed+'\\n',\n",
    "    'aco_ants '+ants+'\\n',\n",
    "    'flip_amide_bonds 0\\n',\n",
    "    'flip_planar_n 1\\n',\n",
    "    'force_flipped_bonds_planarity 0\\n',\n",
    "    'force_planar_bond_rotation 1\\n',\n",
    "    'rescore_mode simplex\\n',\n",
    "    'flip_ring_corners 0\\n',\n",
    "    '# scoring functions\\n',\n",
    "    '# Intermolecular (protein-ligand interaction scoring)\\n',\n",
    "    'scoring_function '+plants_docking_scoring+'\\n',\n",
    "    'outside_binding_site_penalty 50.0\\n',\n",
    "    'enable_sulphur_acceptors 1\\n',\n",
    "    '# Intramolecular ligand scoring\\n',\n",
    "    'ligand_intra_score clash2\\n',\n",
    "    'chemplp_clash_include_14 1\\n',\n",
    "    'chemplp_clash_include_HH 0\\n',\n",
    "\n",
    "    '# input\\n',\n",
    "    'protein_file '+plants_protein_mol2+'\\n',\n",
    "    'ligand_file '+plants_ligands_mol2+'\\n',\n",
    "\n",
    "    '# output\\n',\n",
    "    'output_dir '+plants_docking_results_dir+'\\n',\n",
    "\n",
    "    '# write single mol2 files (e.g. for RMSD calculation)\\n',\n",
    "    'write_multi_mol2 1\\n',\n",
    "\n",
    "    '# binding site definition\\n',\n",
    "    'bindingsite_center '+binding_site_x+' '+binding_site_y+' '+binding_site_z+'+\\n',\n",
    "    'bindingsite_radius '+binding_site_radius+'\\n',\n",
    "\n",
    "    '# cluster algorithm\\n',\n",
    "    'cluster_structures 10\\n',\n",
    "    'cluster_rmsd 2.0\\n',\n",
    "\n",
    "    '# write\\n',\n",
    "    'write_ranking_links 0\\n',\n",
    "    'write_protein_bindingsite 1\\n',\n",
    "    'write_protein_conformations 1\\n',\n",
    "    'write_protein_splitted 1\\n',\n",
    "    'write_merged_protein 0\\n',\n",
    "    '####\\n']\n",
    "    #Write config file\n",
    "    plants_docking_config_path_config = plants_docking_config_path_txt.replace(\".txt\", \".config\")\n",
    "    with open(plants_docking_config_path_config, 'w') as configwriter:\n",
    "        configwriter.writelines(plants_config)\n",
    "    configwriter.close()\n",
    "    # os.rename(plants_docking_config_path_txt, plants_docking_config_path_config)\n",
    "    #Run PLANTS docking\n",
    "    plants_docking_command = \"cd \"+software+\" && ./PLANTS --mode screen \"+plants_docking_config_path_config\n",
    "    os.system(plants_docking_command)\n",
    "    return\n",
    "\n",
    "plants_docking_command, binding_site_x, binding_site_y, binding_site_z, binding_site_radius = plants_docking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. LeDock docking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_box(selection='sele', extending = 6.0):\n",
    "#     ([minX, minY, minZ],[maxX, maxY, maxZ]) = cmd.get_extent(selection)\n",
    "#     minX = minX - float(extending)\n",
    "#     minY = minY - float(extending)\n",
    "#     minZ = minZ - float(extending)\n",
    "#     maxX = maxX + float(extending)\n",
    "#     maxY = maxY + float(extending)\n",
    "#     maxZ = maxZ + float(extending)      \n",
    "#     SizeX = maxX - minX\n",
    "#     SizeY = maxY - minY\n",
    "#     SizeZ = maxZ - minZ\n",
    "#     CenterX =  (maxX + minX)/2\n",
    "#     CenterY =  (maxY + minY)/2\n",
    "#     CenterZ =  (maxZ + minZ)/2        \n",
    "#     cmd.delete('all')        \n",
    "#     return minX, maxX, minY, maxY, minZ, maxZ, CenterX, CenterY, CenterZ\n",
    "# cmd.load(filename=ref_file,format=str(pathlib.Path(ref_file).suffix)[1:],object='lig')\n",
    "# minX, maxX, minY, maxY, minZ, maxZ, CenterX, CenterY, CenterZ = get_box(selection='lig')\n",
    "# print(CenterX, CenterY, CenterZ)\n",
    "# print(binding_site_x, binding_site_y, binding_site_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders (title is /home/tony/Documents/consensus_docking_python/temp/ledock/ligands/FCG16141527_LeDock_7.pdb)\n",
      "\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders (title is /home/tony/Documents/consensus_docking_python/temp/ledock/ligands/FCG16141527_LeDock_1.pdb)\n",
      "\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders (title is /home/tony/Documents/consensus_docking_python/temp/ledock/ligands/FCG16141527_LeDock_2.pdb)\n",
      "\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders (title is /home/tony/Documents/consensus_docking_python/temp/ledock/ligands/FCG16141527_LeDock_6.pdb)\n",
      "\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders (title is /home/tony/Documents/consensus_docking_python/temp/ledock/ligands/FCG16141527_LeDock_8.pdb)\n",
      "\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders (title is /home/tony/Documents/consensus_docking_python/temp/ledock/ligands/FCG16141527_LeDock_10.pdb)\n",
      "\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders (title is /home/tony/Documents/consensus_docking_python/temp/ledock/ligands/FCG16141527_LeDock_9.pdb)\n",
      "\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders (title is /home/tony/Documents/consensus_docking_python/temp/ledock/ligands/FCG16141527_LeDock_5.pdb)\n",
      "\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "1 molecule converted\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders (title is /home/tony/Documents/consensus_docking_python/temp/ledock/ligands/FCG16141527_LeDock_3.pdb)\n",
      "\n",
      "1 molecule converted\n",
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders (title is /home/tony/Documents/consensus_docking_python/temp/ledock/ligands/FCG16141527_LeDock_4.pdb)\n",
      "\n",
      "1 molecule converted\n"
     ]
    }
   ],
   "source": [
    "def ledock_docking():\n",
    "    # Make LeDock temp folders\n",
    "    final_library = root_dir+'/final_library.sdf'\n",
    "    ledock_folder = root_dir+'/temp/ledock/'\n",
    "    ledock_ligands_folder = root_dir+'/temp/ledock/ligands/'\n",
    "    try:\n",
    "        os.mkdir(ledock_folder, mode = 0o777)\n",
    "    except:\n",
    "        print('LeDock root folder already exists')\n",
    "    try:\n",
    "        os.mkdir(ledock_ligands_folder, mode = 0o777)\n",
    "    except:\n",
    "        print('LeDock ligand folder already exists')\n",
    "    #Prepare protein using LePro\n",
    "    try:\n",
    "        lepro_command = \"cd \"+software+\" && ./lepro_linux_x86 \"+protein_file+\" -metal -rot\"\n",
    "        os.system(lepro_command)\n",
    "        shutil.move(software+\"pro.pdb\", ledock_folder+\"pro.pdb\")\n",
    "        lepro_file = ledock_folder+\"pro.pdb\"\n",
    "    except:\n",
    "        print('LePro command failed!')\n",
    "    #Split ligands into sdf files\n",
    "    full_sdf = PandasTools.LoadSDF(final_library, idName=id_column, molColName='Molecule',includeFingerprints=False, embedProps=False, removeHs=False, strictParsing=True)\n",
    "    for i, row in full_sdf.iterrows():\n",
    "        id = row[id_column]\n",
    "        path = ledock_ligands_folder+id+\".sdf\"\n",
    "        single_sdf=full_sdf.loc[full_sdf[id_column]==id]\n",
    "        PandasTools.WriteSDF(single_sdf, path, molColName='Molecule', idName=id_column, properties=None, allNumeric=False)\n",
    "    #Convert ligand sdf files to mol2 files\n",
    "    sdf_list = os.listdir(ledock_ligands_folder)\n",
    "    path_list = []\n",
    "    for x in sdf_list:\n",
    "        y = ledock_ligands_folder+x\n",
    "        path_list.append(y)\n",
    "    for z in path_list:\n",
    "        try:\n",
    "            obabel_command = 'obabel -isdf '+z+' -O '+z.replace(\".sdf\", \".mol2\")\n",
    "            os.system(obabel_command)\n",
    "            os.remove(z)\n",
    "        except:\n",
    "            print('ERROR: Failed to convert library file to .mol2!')\n",
    "    def get_box(selection='sele', extending = 6.0):\n",
    "        ([minX, minY, minZ],[maxX, maxY, maxZ]) = cmd.get_extent(selection)\n",
    "        minX = minX - float(extending)\n",
    "        minY = minY - float(extending)\n",
    "        minZ = minZ - float(extending)\n",
    "        maxX = maxX + float(extending)\n",
    "        maxY = maxY + float(extending)\n",
    "        maxZ = maxZ + float(extending)      \n",
    "        SizeX = maxX - minX\n",
    "        SizeY = maxY - minY\n",
    "        SizeZ = maxZ - minZ\n",
    "        CenterX =  (maxX + minX)/2\n",
    "        CenterY =  (maxY + minY)/2\n",
    "        CenterZ =  (maxZ + minZ)/2        \n",
    "        cmd.delete('all')        \n",
    "        return minX, maxX, minY, maxY, minZ, maxZ\n",
    "    cmd.load(filename=ref_file,format=str(pathlib.Path(ref_file).suffix)[1:],object='lig')\n",
    "    minX, maxX, minY, maxY, minZ, maxZ = get_box(selection='lig')\n",
    "    #Generate LeDock docking file\n",
    "    ledock_ligand_list = root_dir+\"/temp/ledock/ligands.list\"\n",
    "    with open(ledock_ligand_list,'w') as l_out:\n",
    "        for element in os.listdir(ledock_ligands_folder):\n",
    "            writer = (ledock_ligands_folder+element).replace(\".sdf\", \".mol2\")+'\\n'\n",
    "            l_out.write(writer)\n",
    "    l_out.close()\n",
    "    lepro_file = ledock_folder+\"pro.pdb\"\n",
    "    file=[\n",
    "        'Receptor\\n',\n",
    "        lepro_file + '\\n\\n',\n",
    "        'RMSD\\n',\n",
    "        '1.0\\n\\n',\n",
    "        'Binding pocket\\n',\n",
    "        str(minX),' ',str(maxX),'\\n',\n",
    "        str(minY),' ',str(maxY),'\\n',\n",
    "        str(minZ),' ',str(maxZ),'\\n\\n',\n",
    "        'Number of binding poses\\n',\n",
    "        str(n_poses+1 ) + '\\n\\n',\n",
    "        'Ligands list\\n',\n",
    "        ledock_ligand_list + '\\n\\n',\n",
    "        'END']\n",
    "    #Write LeDock config file\n",
    "    ledock_config = root_dir+\"/temp/ledock/dock.in\"\n",
    "    with open(ledock_config,'w') as ledock_config_output:\n",
    "        for line in file:\n",
    "            ledock_config_output.write(line)\n",
    "    ledock_config_output.close()\n",
    "    #Run LeDock\n",
    "    ledock_docking_command = \"cd \"+software+\" && ./ledock_linux_x86 \"+ledock_config\n",
    "    os.system(ledock_docking_command)\n",
    "    #Remove .mol2 files\n",
    "    for x in os.listdir(ledock_ligands_folder):\n",
    "        if x.endswith('.mol2'):\n",
    "            os.remove(ledock_ligands_folder+x)\n",
    "        else:\n",
    "            pass\n",
    "    ledock_ligands_folder = root_dir+'/temp/ledock/ligands/'\n",
    "    #Get .dok files\n",
    "    ledock_dok_files = []\n",
    "    for file in os.listdir(ledock_ligands_folder):\n",
    "        if file.endswith(\".dok\"):\n",
    "            dok = ledock_ligands_folder+file\n",
    "            ledock_dok_files.append(dok)\n",
    "    #Split .dok files into .txt\n",
    "    for x in ledock_dok_files:\n",
    "        op = ''\n",
    "        start = 0\n",
    "        counter = 1\n",
    "        file_name = x.replace(root_dir+\"/temp/ledock/ligands/\", \"\")\n",
    "        file_name = file_name.replace(\".dok\", \"\")\n",
    "        file_name = file_name+\"_LeDock_\"\n",
    "        with open(x, 'r') as f:\n",
    "            for x in f.read().split('\\n'):\n",
    "                if x.__contains__(\"Cluster\"):\n",
    "                    if (start==1):\n",
    "                        with open(ledock_ligands_folder+\"/\"+file_name+str(counter)+\".txt\", \"w\") as output_file:\n",
    "                            output_file.write(op)\n",
    "                            op=''\n",
    "                            counter+=1\n",
    "                    else:\n",
    "                        start=1\n",
    "                else:\n",
    "                    op = op+'\\n'+x\n",
    "    #Fix .txt files\n",
    "    ledock_txt_files = []\n",
    "    for file in os.listdir(ledock_ligands_folder):\n",
    "        if file.endswith(\".txt\"):\n",
    "            txt = ledock_ligands_folder+file\n",
    "            ledock_txt_files.append(txt)\n",
    "        else:\n",
    "            pass\n",
    "    for y in ledock_txt_files:\n",
    "        new=[\"NEW FILE START\\n\"]\n",
    "        new_file = y.replace(\".txt\", \"_cleaned.txt\")\n",
    "        with open(y, 'r') as txt_file:\n",
    "            for line in txt_file.read().split('\\n'):\n",
    "                if line.__contains__(\"ATOM\"):\n",
    "                    line=line+'\\n'\n",
    "                    new.append(line)\n",
    "                else:\n",
    "                    pass\n",
    "            txt_file.close()\n",
    "            new.append(\"END\\n\")\n",
    "            os.remove(y)\n",
    "        with open(new_file, 'w') as out_file:\n",
    "            for lines in new:\n",
    "                out_file.write(lines)\n",
    "            out_file.close()\n",
    "    ledock_cleaned_files = []\n",
    "    for file in os.listdir(ledock_ligands_folder):\n",
    "        if file.endswith(\".txt\"):\n",
    "            cleaned = ledock_ligands_folder+file\n",
    "            ledock_cleaned_files.append(cleaned)\n",
    "        else:\n",
    "            pass\n",
    "    for input in ledock_cleaned_files:   \n",
    "        ledock_pdb=input.replace(\"cleaned\", \"mod\")\n",
    "        with open(input, 'r') as f:\n",
    "            doc=[line for line in f.readlines()]\n",
    "        doc=[line.replace(line.split()[2],line.split()[2].upper()) if 'ATOM' in line else line for line in doc]\n",
    "        start=[index for (index,p) in enumerate(doc) if 'NEW FILE' in p]\n",
    "        finish=[index-1 for (index,p) in enumerate(doc) if 'NEW FILE' in p]\n",
    "        finish.append(len(doc))\n",
    "        interval=list(zip(start,finish[1:]))\n",
    "        for num,i in enumerate(interval):\n",
    "            block = \",\".join(doc[i[0]:i[1]]).replace(',','')\n",
    "            with open(ledock_pdb, 'w') as w:\n",
    "                w.write(block)\n",
    "    for file in os.listdir(ledock_ligands_folder):\n",
    "        file = root_dir+\"/temp/ledock/ligands/\"+file\n",
    "        if file.endswith(\"_cleaned.txt\"):\n",
    "            os.remove(file)\n",
    "    for file in os.listdir(ledock_ligands_folder):\n",
    "        if file.endswith(\"_mod.txt\"):\n",
    "            id = file.replace(\"_mod.txt\", \"\")\n",
    "            output = str(root_dir+\"/temp/ledock/ligands/\"+id+\".pdb\")\n",
    "            with open(str(root_dir+\"/temp/ledock/ligands/\"+file), 'rt') as i:\n",
    "                lines = i.readlines()\n",
    "                test = []\n",
    "                for l in lines:\n",
    "                    if l.__contains__('NEW FILE'):\n",
    "                        l = l.replace(\"NEW FILE START\\n\", \"HEADER\\nTITLE     \"+id+'\\n')\n",
    "                        test.append(l)\n",
    "                    if l.__contains__('ATOM'):\n",
    "                        line_part_1 = l.split()\n",
    "                        line_part_2 = l[30:53]\n",
    "                        if len(str(line_part_1[1]))>1:\n",
    "                            pass\n",
    "                        if len(str(line_part_1[1]))==1:\n",
    "                            fixed_atom_num = ' '+str(line_part_1[1])\n",
    "                            line_part_1[1] = fixed_atom_num\n",
    "                        if len(line_part_1[2])>1:\n",
    "                            pass\n",
    "                        if len(line_part_1[2])==1:\n",
    "                            fixed_atom_code = ' '+line_part_1[2]\n",
    "                            line_part_1[2] = fixed_atom_code\n",
    "                        new_line = line_part_1[0]+'     '+line_part_1[1]+' '+line_part_1[2]+'   '+line_part_1[3]+'     '+line_part_1[4]+'    '+line_part_2+'                       '+line_part_1[2]+'\\n'\n",
    "                        test.append(new_line)\n",
    "                output_string = ''\n",
    "                for t in test:\n",
    "                    output_string = output_string+t\n",
    "                with open(output, 'wt') as o:\n",
    "                    o.write(output_string)\n",
    "    #Convert to .sdf and remove .dok files\n",
    "    ledock_pdb_files = []\n",
    "    for file in os.listdir(ledock_ligands_folder):\n",
    "        if file.endswith(\".pdb\"):\n",
    "            pdb = ledock_ligands_folder+file\n",
    "            ledock_pdb_files.append(pdb)\n",
    "        if file.endswith('.dok'):\n",
    "            os.remove(ledock_ligands_folder+file)\n",
    "        else:\n",
    "            pass\n",
    "    for file in ledock_pdb_files:\n",
    "        try:\n",
    "            obabel_command = 'obabel -ipdb '+file+' -O '+file.replace(\".pdb\", \".sdf\")\n",
    "            os.system(obabel_command)\n",
    "            os.remove(file)\n",
    "        except:\n",
    "            print('ERROR: Failed to convert library file to .sdf!')\n",
    "    #Concatenate .sdf files\n",
    "    df = pd.DataFrame()\n",
    "    ledock_sdf_files = []\n",
    "    for file in os.listdir(ledock_ligands_folder):\n",
    "        if file.endswith(\".sdf\"):\n",
    "            sdf = ledock_ligands_folder+file\n",
    "            ledock_sdf_files.append(sdf)\n",
    "        else:\n",
    "            pass\n",
    "    for sdf in ledock_sdf_files:\n",
    "        df1 = PandasTools.LoadSDF(sdf, idName='TITLE', molColName='Structure',includeFingerprints=False, embedProps=False, removeHs=False, strictParsing=False)\n",
    "        df = pd.concat([df, df1])\n",
    "    df = df.rename(columns={'TITLE':'Pose ID'})\n",
    "    df = df.rename(columns={'HEADER':'ID'})\n",
    "    for i, row in df.iterrows():\n",
    "        row['Pose ID'] = row['Pose ID'].replace(root_dir+\"/temp/ledock/ligands/\", \"\")\n",
    "        row[id_column] = row['Pose ID'].split('_')[0]\n",
    "        row['Pose ID'] = row['Pose ID'].replace(\".pdb\", \"\")\n",
    "    PandasTools.WriteSDF(df, root_dir+\"/temp/ledock/ligands/all_poses.sdf\", molColName='Structure', idName='Pose ID', properties=list(df.columns), allNumeric=True)\n",
    "    #Remove extra .sdf files\n",
    "    ledock_extra_files = []\n",
    "    for file in os.listdir(ledock_ligands_folder):\n",
    "        if \"_LeDock_\" in file:\n",
    "            sdf = ledock_ligands_folder+file\n",
    "            ledock_extra_files.append(sdf)\n",
    "    for file in ledock_extra_files:\n",
    "        os.remove(file)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    result = executor.submit(ledock_docking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Concatenate poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "*** Open Babel Warning  in ReadMolecule\n",
      "  Failed to kekulize aromatic bonds in MOL2 file (title is FCG16600623_entry_00004_conf_01)\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in ReadMolecule\n",
      "  Failed to kekulize aromatic bonds in MOL2 file (title is FCG16600623_entry_00004_conf_02)\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in ReadMolecule\n",
      "  Failed to kekulize aromatic bonds in MOL2 file (title is FCG16600623_entry_00004_conf_03)\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in ReadMolecule\n",
      "  Failed to kekulize aromatic bonds in MOL2 file (title is FCG16600623_entry_00004_conf_04)\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in ReadMolecule\n",
      "  Failed to kekulize aromatic bonds in MOL2 file (title is FCG16600623_entry_00004_conf_05)\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in ReadMolecule\n",
      "  Failed to kekulize aromatic bonds in MOL2 file (title is FCG16600623_entry_00004_conf_06)\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in ReadMolecule\n",
      "  Failed to kekulize aromatic bonds in MOL2 file (title is FCG16600623_entry_00004_conf_07)\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in ReadMolecule\n",
      "  Failed to kekulize aromatic bonds in MOL2 file (title is FCG16600623_entry_00004_conf_08)\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in ReadMolecule\n",
      "  Failed to kekulize aromatic bonds in MOL2 file (title is FCG16600623_entry_00004_conf_09)\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in ReadMolecule\n",
      "  Failed to kekulize aromatic bonds in MOL2 file (title is FCG16600623_entry_00004_conf_10)\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in ReadMolecule\n",
      "  Failed to kekulize aromatic bonds in MOL2 file (title is FCG17585042_entry_00007_conf_01)\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in ReadMolecule\n",
      "  Failed to kekulize aromatic bonds in MOL2 file (title is FCG17585042_entry_00007_conf_02)\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in ReadMolecule\n",
      "  Failed to kekulize aromatic bonds in MOL2 file (title is FCG17585042_entry_00007_conf_03)\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in ReadMolecule\n",
      "  Failed to kekulize aromatic bonds in MOL2 file (title is FCG17585042_entry_00007_conf_04)\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in ReadMolecule\n",
      "  Failed to kekulize aromatic bonds in MOL2 file (title is FCG17585042_entry_00007_conf_05)\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in ReadMolecule\n",
      "  Failed to kekulize aromatic bonds in MOL2 file (title is FCG17585042_entry_00007_conf_06)\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in ReadMolecule\n",
      "  Failed to kekulize aromatic bonds in MOL2 file (title is FCG17585042_entry_00007_conf_07)\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in ReadMolecule\n",
      "  Failed to kekulize aromatic bonds in MOL2 file (title is FCG17585042_entry_00007_conf_08)\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in ReadMolecule\n",
      "  Failed to kekulize aromatic bonds in MOL2 file (title is FCG17585042_entry_00007_conf_09)\n",
      "\n",
      "==============================\n",
      "*** Open Babel Warning  in ReadMolecule\n",
      "  Failed to kekulize aromatic bonds in MOL2 file (title is FCG17585042_entry_00007_conf_10)\n",
      "\n",
      "100 molecules converted\n"
     ]
    }
   ],
   "source": [
    "def fetch_poses():\n",
    "    plants_docking_results_mol2 = root_dir+\"/temp/plants/results/docked_ligands.mol2\"\n",
    "    plants_docking_results_sdf = plants_docking_results_mol2.replace(\".mol2\", \".sdf\")\n",
    "    # Convert PLANTS poses to sdf\n",
    "    try:\n",
    "        obabel_command = 'obabel -imol2 '+plants_docking_results_mol2+' -O '+plants_docking_results_sdf \n",
    "        os.system(obabel_command)\n",
    "    except:\n",
    "        print('ERROR: Failed to convert PLANTS poses file to .sdf!')\n",
    "    smina_docking_results = root_dir+\"/temp/smina/docked.sdf\"\n",
    "    gnina_docking_results = root_dir+\"/temp/gnina/docked.sdf\"\n",
    "    #Fetch PLANTS poses\n",
    "    try:\n",
    "        plants_df = PandasTools.LoadSDF(plants_docking_results_sdf, idName=id_column, molColName='Molecule',includeFingerprints=False, embedProps=False, removeHs=False, strictParsing=True)\n",
    "        for i, row in plants_df.iterrows():\n",
    "            split = row[id_column].split(\"_\")\n",
    "            conformer_id = str(split[4])\n",
    "            plants_df.loc[i, ['Pose ID']] = split[0]+\"_PLANTS_\"+conformer_id\n",
    "            plants_df.loc[i, ['ID']] = split[0]\n",
    "    except:\n",
    "        print('ERROR: Failed to Load PLANTS poses SDF file!')\n",
    "    #Fetch SMINA poses\n",
    "    try:\n",
    "        smina_df = PandasTools.LoadSDF(smina_docking_results, idName=id_column, molColName='Molecule',includeFingerprints=False, embedProps=False, removeHs=False, strictParsing=True)\n",
    "        smina_df = smina_df[[id_column, 'Molecule']]\n",
    "        list_ = [*range(1, n_poses+1, 1)]\n",
    "        ser = list_ * int(len(smina_df)/len(list_))\n",
    "        smina_df['number'] = ser + list_[:len(smina_df)-len(ser)]\n",
    "        for i, row in smina_df.iterrows():\n",
    "            smina_df.loc[i, ['Pose ID']] = row[id_column]+\"_SMINA_\"+str(row['number'])\n",
    "        smina_df.drop('number', axis=1, inplace=True)\n",
    "    except:\n",
    "        print('ERROR: Failed to Load SMINA poses SDF file!')\n",
    "    #Fetch GNINA poses\n",
    "    try:\n",
    "        gnina_df = PandasTools.LoadSDF(gnina_docking_results, idName=id_column, molColName='Molecule',includeFingerprints=False, embedProps=False, removeHs=False, strictParsing=True)\n",
    "        gnina_df = gnina_df[[id_column, 'Molecule']]\n",
    "        list_ = [*range(1, n_poses+1, 1)]\n",
    "        ser = list_ * int(len(gnina_df)/len(list_))\n",
    "        gnina_df['number'] = ser + list_[:len(gnina_df)-len(ser)]\n",
    "        for i, row in gnina_df.iterrows():\n",
    "            gnina_df.loc[i, ['Pose ID']] = row[id_column]+\"_GNINA_\"+str(row['number'])\n",
    "        gnina_df.drop('number', axis=1, inplace=True)\n",
    "    except:\n",
    "        print('ERROR: Failed to Load GNINA poses SDF file!')\n",
    "    #Fetch LeDock poses\n",
    "    ledock_docking_results = root_dir+\"/temp/ledock/ligands/all_poses.sdf\"\n",
    "    try:\n",
    "        ledock_df = PandasTools.LoadSDF(ledock_docking_results, idName='Pose ID', molColName='Molecule',includeFingerprints=False, embedProps=False, removeHs=False, strictParsing=True)\n",
    "    except:\n",
    "        print('ERROR: Failed to Load GNINA poses SDF file!')\n",
    "    #Concatenate all poses to single dataframe\n",
    "    all_poses = pd.concat([plants_df, smina_df, gnina_df, ledock_df], ignore_index=True)\n",
    "    return (all_poses)\n",
    "\n",
    "all_poses = fetch_poses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set _Name property for all poses\n",
    "poses=all_poses['Molecule']\n",
    "renamed_poses=[]\n",
    "for i,row in all_poses.iterrows():\n",
    "\tp = row['Molecule']\n",
    "\tp.SetProp('_Name',str(row['Pose ID']))\n",
    "\trenamed_poses.append(p)\n",
    "all_poses['Molecule'] = renamed_poses\n",
    "PandasTools.WriteSDF(all_poses, root_dir+\"/temp/allposes.sdf\", molColName='Molecule', idName='Pose ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering metrics folder already exists\n",
      "Clustering folder already exists\n"
     ]
    }
   ],
   "source": [
    "clustering_metrics_folder = root_dir+'/temp/clustering_metrics/'\n",
    "try:\n",
    "    os.mkdir(clustering_metrics_folder)\n",
    "except:\n",
    "    print('Clustering metrics folder already exists')\n",
    "\n",
    "clustering_folder = root_dir+'/temp/clustering/'\n",
    "try:\n",
    "    os.mkdir(clustering_folder)\n",
    "except:\n",
    "    print('Clustering folder already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Functions for clustering metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleRMSD(dataframe):\n",
    "    size=len(dataframe)\n",
    "    table=pd.DataFrame()\n",
    "    for i,row in tqdm(dataframe.iterrows()):\n",
    "        for j,jrow in dataframe.iterrows():\n",
    "            mol = row['Molecule']\n",
    "            jmol = jrow['Molecule']\n",
    "            # MCS identification between reference pose and target pose\n",
    "            r=rdFMCS.FindMCS([mol,jmol])\n",
    "            # Atom map for reference and target              \n",
    "            a=mol.GetSubstructMatch(Chem.MolFromSmarts(r.smartsString))\n",
    "            b=jmol.GetSubstructMatch(Chem.MolFromSmarts(r.smartsString))\n",
    "            # Atom map generation     \n",
    "            amap=list(zip(a,b))\n",
    "            # distance calculation per atom pair\n",
    "            distances=[]\n",
    "            for atomA, atomB in amap:\n",
    "                pos_A=mol.GetConformer().GetAtomPosition (atomA)\n",
    "                pos_B=jmol.GetConformer().GetAtomPosition (atomB)\n",
    "                coord_A=np.array((pos_A.x,pos_A.y,pos_A.z))\n",
    "                coord_B=np.array ((pos_B.x,pos_B.y,pos_B.z))\n",
    "                dist_numpy = np.linalg.norm(coord_A-coord_B)        \n",
    "                distances.append(dist_numpy)      \n",
    "            # This is the RMSD formula from wikipedia\n",
    "            rmsd=math.sqrt(1/len(distances)*sum([i*i for i in distances])) \n",
    "            #saving the rmsd values to a matrix and a table for clustering\n",
    "            table.loc[mol.GetProp('_Name'),jmol.GetProp('_Name')]=rmsd\n",
    "    return table\n",
    "\n",
    "def spyRMSD(path_list):\n",
    "  table=pd.DataFrame()\n",
    "  for mol in tqdm(enumerate(path_list)):\n",
    "      for jmol in enumerate(path_list):\n",
    "          ref = io.loadmol(mol[1])\n",
    "          test = io.loadmol(jmol[1])\n",
    "          ref.strip()\n",
    "          test.strip()\n",
    "          coords_ref = ref.coordinates\n",
    "          anum_ref = ref.atomicnums\n",
    "          adj_ref = ref.adjacency_matrix\n",
    "          coords_test = test.coordinates\n",
    "          anum_test = test.atomicnums\n",
    "          adj_test = test.adjacency_matrix\n",
    "          spyrmsd = rmsd.symmrmsd(coords_ref,coords_test,anum_ref,anum_test,adj_ref,adj_test)\n",
    "          id = mol[1].replace(clustering_metrics_folder, \"\").replace(\".sdf\", \"\")\n",
    "          jid = jmol[1].replace(clustering_metrics_folder, \"\").replace(\".sdf\", \"\")\n",
    "          table.loc[id, jid]=spyrmsd\n",
    "  return table\n",
    "\n",
    "def espsim_default(dataframe):\n",
    "\tsize=len(dataframe)\n",
    "\thmap=np.empty(shape=(size,size))\n",
    "\ttable=pd.DataFrame()\n",
    "\tfor i, row in tqdm(dataframe.iterrows()):\n",
    "\t\tfor j, jrow in dataframe.iterrows():\n",
    "\t\t\tmol = row['Molecule']\n",
    "\t\t\tjmol = jrow['Molecule']\n",
    "\t\t\tid = row['Pose ID']\n",
    "\t\t\tjid = jrow['Pose ID']\n",
    "\t\t\tespsim = GetEspSim(mol, jmol, renormalize=True)\n",
    "\t\t\ttable.loc[id,jid]=espsim\n",
    "\treturn table\n",
    "\n",
    "def espsim_mmff(dataframe):\n",
    "\tsize=len(dataframe)\n",
    "\thmap=np.empty(shape=(size,size))\n",
    "\ttable=pd.DataFrame()\n",
    "\tfor i, row in tqdm(dataframe.iterrows()):\n",
    "\t\tfor j, jrow in dataframe.iterrows():\n",
    "\t\t\tmol = row['Molecule']\n",
    "\t\t\tjmol = jrow['Molecule']\n",
    "\t\t\tid = row['Pose ID']\n",
    "\t\t\tjid = jrow['Pose ID']\n",
    "\t\t\tespsim = GetEspSim(mol, jmol, partialCharges = 'mmff', renormalize=True)\n",
    "\t\t\ttable.loc[id,jid]=espsim\n",
    "\treturn table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Clustering methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmedoids_E_clustering(input_dataframe):\n",
    "\tdataframe = input_dataframe.copy()\n",
    "\t# Get column names for renaming\n",
    "\tcolumn_list = dataframe.columns.tolist()\n",
    "\t# Calculate maximum number of clusters\n",
    "\tif len(dataframe)>20:\n",
    "\t\tmax_clusters = 20\n",
    "\telse:\n",
    "\t\tmax_clusters = len(dataframe)\n",
    "\t# Define function for inertia/sum of squares calculation\n",
    "\tdef calculate_ss(data):\n",
    "\t\twcss = []\n",
    "\t\tfor n in range(2, max_clusters):\n",
    "\t\t\tkmedoids = KMedoids(n_clusters=n, init='heuristic')\n",
    "\t\t\tkmedoids.fit(X=dataframe)\n",
    "\t\t\twcss.append(kmedoids.inertia_)\n",
    "\t\treturn wcss\n",
    "\t# Calculate sum of squares and range for k\n",
    "\tsum_of_squares = calculate_ss(dataframe)\n",
    "\tcluster_range = range(2, max_clusters)\n",
    "\t# Determine elbow value\n",
    "\tkn = KneeLocator(cluster_range, sum_of_squares, curve='convex', direction='decreasing')\n",
    "\tif kn.knee is None:\n",
    "\t\topt_clusters = 5\n",
    "\telse:\n",
    "\t\topt_clusters = 5\n",
    "\t#Plotting\n",
    "\tplt.xlabel('k')\n",
    "\tplt.ylabel('Sum of squared distances')\n",
    "\tplt.plot(cluster_range, sum_of_squares, 'bx-')\n",
    "\tplt.vlines(kn.knee, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\n",
    "\t# Apply optimised k-medoids clustering\n",
    "\tkmedoids = KMedoids(n_clusters=opt_clusters, init='heuristic')\n",
    "\tclusters = kmedoids.fit_predict(dataframe)\n",
    "\tdataframe['KMedoids Cluster']=clusters\n",
    "\t# Determine centers\n",
    "\tcenters_array = kmedoids.cluster_centers_\n",
    "\tcluster_centers = pd.DataFrame(centers_array, columns = column_list)\n",
    "\t# Assign IDs to cluster centers\n",
    "\tcluster_centers['Pose ID'] = \"NaN\"\n",
    "\tdataframe['Pose ID'] = \"NaN\"\n",
    "\tfor i, row in dataframe.iterrows():\n",
    "\t\tdataframe.loc[i, 'Pose ID'] = i\n",
    "\tfor j, jrow in cluster_centers.iterrows():\n",
    "\t\tfor x in enumerate(cluster_centers.columns):\n",
    "\t\t\tif jrow[x[1]]==1 or jrow[x[1]]==0:\n",
    "\t\t\t\tcluster_centers.loc[j, 'Pose ID'] = x[1]\n",
    "\t\t\telse:\n",
    "\t\t\t\tpass\n",
    "\t# Remove columns used for clustering\n",
    "\tcluster_centers_cleaned = cluster_centers[['Pose ID']]\n",
    "\tcluster_centers_cleaned = cluster_centers_cleaned.merge(dataframe, on='Pose ID')\n",
    "\tcluster_centers_cleaned = cluster_centers_cleaned.merge(all_poses, on='Pose ID')\n",
    "\tcluster_centers_cleaned = cluster_centers_cleaned.drop(columns=column_list)\n",
    "\treturn cluster_centers_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmedoids_S_clustering(input_dataframe):\n",
    "\tdataframe = input_dataframe.copy()\n",
    "\t# Get column names for renaming\n",
    "\tcolumn_list = dataframe.columns.tolist()\n",
    "\t# Calculate maximum number of clusters\n",
    "\tif len(dataframe)>20:\n",
    "\t\tmax_clusters = 20\n",
    "\telse:\n",
    "\t\tmax_clusters = len(dataframe)\n",
    "\trange_n_clusters = range(2,max_clusters)\n",
    "\t# Define function for silhouette calculation\n",
    "\tsilhouettes = []\n",
    "\tfor n_clusters in range_n_clusters:\n",
    "\t\tclusterer = KMedoids(n_clusters=n_clusters, init='heuristic')\n",
    "\t\tcluster_labels = clusterer.fit_predict(dataframe)\n",
    "\t\tsilhouette_n = silhouette_score(dataframe, cluster_labels)\n",
    "\t\tsilhouettes.append(silhouette_n)\n",
    "\tsilhouette_df = pd.DataFrame(columns=['n', 'silhouette_score'])\n",
    "\tsilhouette_df['n'] = range_n_clusters\n",
    "\tsilhouette_df['silhouette_score'] = silhouettes\n",
    "\topt_clusters = int(silhouette_df.loc[silhouette_df['silhouette_score'].idxmax(), ['n']][0])\n",
    "\t# Plot\n",
    "\tplt.xlabel('k')\n",
    "\tplt.ylabel('silhouettes')\n",
    "\tplt.plot(np.array(silhouette_df['n']), np.array(silhouette_df['silhouette_score']), 'bx-')\n",
    "\tplt.vlines(opt_clusters, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\n",
    "\t# Apply optimised k-medoids clustering\n",
    "\tkmedoids = KMedoids(n_clusters=opt_clusters, init='heuristic')\n",
    "\tclusters = kmedoids.fit_predict(dataframe)\n",
    "\tdataframe['KMedoids Cluster']=clusters\n",
    "\t# Determine centers\n",
    "\tcenters_array = kmedoids.cluster_centers_\n",
    "\tcluster_centers = pd.DataFrame(centers_array, columns = column_list)\n",
    "\t# Assign IDs to cluster centers\n",
    "\tcluster_centers['Pose ID'] = \"NaN\"\n",
    "\tdataframe['Pose ID'] = \"NaN\"\n",
    "\tfor i, row in dataframe.iterrows():\n",
    "\t\tdataframe.loc[i, 'Pose ID'] = i\n",
    "\tfor j, jrow in cluster_centers.iterrows():\n",
    "\t\tfor x in enumerate(cluster_centers.columns):\n",
    "\t\t\tif jrow[x[1]]==1 or jrow[x[1]]==0:\n",
    "\t\t\t\tcluster_centers.loc[j, 'Pose ID'] = x[1]\n",
    "\t\t\telse:\n",
    "\t\t\t\tpass\n",
    "\t# Remove columns used for clustering\n",
    "\tcluster_centers_cleaned = cluster_centers[['Pose ID']]\n",
    "\tcluster_centers_cleaned = cluster_centers_cleaned.merge(dataframe, on='Pose ID')\n",
    "\tcluster_centers_cleaned = cluster_centers_cleaned.merge(all_poses, on='Pose ID')\n",
    "\tcluster_centers_cleaned = cluster_centers_cleaned.drop(columns=column_list)\n",
    "\treturn cluster_centers_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FCG1390566' 'FCG16141527' 'FCG16425532' 'FCG16600623' 'FCG16952409'\n",
      " 'FCG17274676' 'FCG17585042' 'FCG17822054' 'FCG18066182' 'FCG18472628']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering FCG1390566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:02, 13.45it/s]\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/10 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3004/988867296.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mRMSD_kE_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspyRMSD_kE_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mespsim_d_kE_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmff_kE_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspyRMSD_mmff_kE_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSD_kS_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspyRMSD_kS_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mespsim_d_kS_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmff_kS_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspyRMSD_mmff_kS_full\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mRMSD_kE_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspyRMSD_kE_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mespsim_d_kE_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmff_kE_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspyRMSD_mmff_kE_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSD_kS_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspyRMSD_kS_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mespsim_d_kS_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmff_kS_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspyRMSD_mmff_kS_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mRMSD_kE_full_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclustering_folder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'RMSD_kE_full.sdf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3004/988867296.py\u001b[0m in \u001b[0;36mclustering\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mfiltered_df_simple_RMSD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimpleRMSD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mcolumn_reordering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_df_simple_RMSD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mfiltered_df_spyRMSD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspyRMSD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mfiltered_df_spyRMSD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_df_spyRMSD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn_reordering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mfiltered_df_espsim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mespsim_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3004/2591622940.py\u001b[0m in \u001b[0;36mspyRMSD\u001b[0;34m(path_list)\u001b[0m\n\u001b[1;32m     42\u001b[0m           \u001b[0manum_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matomicnums\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0madj_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjacency_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m           \u001b[0mspyrmsd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrmsd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymmrmsd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcoords_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manum_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manum_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madj_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madj_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m           \u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_metrics_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".sdf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m           \u001b[0mjid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjmol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_metrics_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".sdf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepdock2/lib/python3.7/site-packages/spyrmsd/rmsd.py\u001b[0m in \u001b[0;36msymmrmsd\u001b[0;34m(coordsref, coords, atomicnumsref, atomicnums, amref, am, center, minimize, cache, atol)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mminimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0misomorphisms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         )\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepdock2/lib/python3.7/site-packages/spyrmsd/rmsd.py\u001b[0m in \u001b[0;36m_rmsd_isomorphic_core\u001b[0;34m(coords1, coords2, atomicnums1, atomicnums2, am1, am2, center, minimize, isomorphisms, atol)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \"\"\"\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcoords1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcoords2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoords1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "id_list = np.unique(np.array(all_poses['ID']))\n",
    "print(id_list)\n",
    "RMSD_kE_full = pd.DataFrame()\n",
    "spyRMSD_kE_full = pd.DataFrame()\n",
    "espsim_d_kE_full = pd.DataFrame()\n",
    "mmff_kE_full = pd.DataFrame()\n",
    "spyRMSD_mmff_kE_full = pd.DataFrame()\n",
    "RMSD_kS_full = pd.DataFrame()\n",
    "spyRMSD_kS_full = pd.DataFrame()\n",
    "espsim_d_kS_full = pd.DataFrame()\n",
    "mmff_kS_full = pd.DataFrame()\n",
    "spyRMSD_mmff_kS_full = pd.DataFrame()\n",
    "\n",
    "@lru_cache(maxsize = 40)\n",
    "def clustering():\n",
    "    for id in tqdm(id_list):\n",
    "        print(\"Clustering \"+id)\n",
    "        filtered_df = all_poses[all_poses.ID==id]\n",
    "        for i, row in filtered_df.iterrows():\n",
    "            single_line = filtered_df[filtered_df.index==i]\n",
    "            pose_path = clustering_metrics_folder+row['Pose ID']+'.sdf'\n",
    "            PandasTools.WriteSDF(single_line, pose_path, molColName='Molecule', idName='Pose ID')\n",
    "        poses = []\n",
    "        for file in os.listdir(clustering_metrics_folder):\n",
    "            poses.append(clustering_metrics_folder+file)\n",
    "        filtered_df_simple_RMSD = simpleRMSD(filtered_df)\n",
    "        column_reordering = filtered_df_simple_RMSD.columns\n",
    "        filtered_df_spyRMSD = spyRMSD(poses)\n",
    "        filtered_df_spyRMSD = filtered_df_spyRMSD.reindex(columns=column_reordering)\n",
    "        filtered_df_espsim = espsim_default(filtered_df)\n",
    "        filtered_df_mmff= espsim_mmff(filtered_df)\n",
    "        filtered_df_spyRMSD_mmff = filtered_df_spyRMSD*filtered_df_mmff\n",
    "        for file in poses:\n",
    "            os.remove(file)\n",
    "        RMSD_kE_centers = kmedoids_E_clustering(filtered_df_simple_RMSD)\n",
    "        spyRMSD_kE_centers = kmedoids_E_clustering(filtered_df_spyRMSD)\n",
    "        espsim_d_kE_centers = kmedoids_E_clustering(filtered_df_espsim)\n",
    "        mmff_kE_centers = kmedoids_E_clustering(filtered_df_mmff)\n",
    "        spyRMSD_mmff_kE_centers = kmedoids_E_clustering(filtered_df_spyRMSD_mmff)\n",
    "        RMSD_kS_centers = kmedoids_S_clustering(filtered_df_simple_RMSD)\n",
    "        spyRMSD_kS_centers = kmedoids_S_clustering(filtered_df_spyRMSD)\n",
    "        espsim_d_kS_centers = kmedoids_S_clustering(filtered_df_espsim)\n",
    "        mmff_kS_centers = kmedoids_S_clustering(filtered_df_mmff)\n",
    "        spyRMSD_mmff_kS_centers = kmedoids_S_clustering(filtered_df_spyRMSD_mmff)\n",
    "\n",
    "        RMSD_kE_full = RMSD_kE_full.append(RMSD_kE_centers)\n",
    "        spyRMSD_kE_full = spyRMSD_kE_full.append(spyRMSD_kE_centers)\n",
    "        espsim_d_kE_full = espsim_d_kE_full.append(espsim_d_kE_centers)\n",
    "        mmff_kE_full = mmff_kE_full.append(mmff_kE_centers)\n",
    "        spyRMSD_mmff_kE_full = spyRMSD_mmff_kE_full.append(spyRMSD_mmff_kE_centers)\n",
    "        RMSD_kS_full = RMSD_kS_full.append(RMSD_kS_centers)\n",
    "        spyRMSD_kS_full = spyRMSD_kS_full.append(spyRMSD_kS_centers)\n",
    "        espsim_d_kS_full = espsim_d_kS_full.append(espsim_d_kS_centers)\n",
    "        mmff_kS_full = mmff_kS_full.append(mmff_kS_centers)\n",
    "        spyRMSD_mmff_kS_full = spyRMSD_mmff_kS_full.append(spyRMSD_mmff_kS_centers)\n",
    "    return RMSD_kE_full, spyRMSD_kE_full, espsim_d_kE_full, mmff_kE_full, spyRMSD_mmff_kE_full, RMSD_kS_full, spyRMSD_kS_full, espsim_d_kS_full, mmff_kS_full, spyRMSD_mmff_kS_full\n",
    "\n",
    "RMSD_kE_full, spyRMSD_kE_full, espsim_d_kE_full, mmff_kE_full, spyRMSD_mmff_kE_full, RMSD_kS_full, spyRMSD_kS_full, espsim_d_kS_full, mmff_kS_full, spyRMSD_mmff_kS_full = clustering()\n",
    "\n",
    "RMSD_kE_full_path = clustering_folder+'RMSD_kE_full.sdf'\n",
    "spyRMSD_kE_full_path = clustering_folder+'spyRMSD_kE_full.sdf'\n",
    "espsim_d_kE_full_path = clustering_folder+'espsim_d_kE_full.sdf'\n",
    "mmff_kE_full_path = clustering_folder+'mmff_kE_full.sdf'\n",
    "spyRMSD_mmff_kE_full_path = clustering_folder+'spyRMSD_mmff_kE_full.sdf'\n",
    "RMSD_kS_full_path = clustering_folder+'RMSD_kS_full.sdf'\n",
    "spyRMSD_kS_full_path = clustering_folder+'spyRMSD_kS_full.sdf'\n",
    "espsim_d_kS_full_path = clustering_folder+'espsim_d_kS_full.sdf'\n",
    "mmff_kS_full_path = clustering_folder+'mmff_kS_full.sdf'\n",
    "spyRMSD_mmff_kS_full_path = clustering_folder+'spyRMSD_mmff_kS_full.sdf'\n",
    "\n",
    "PandasTools.WriteSDF(RMSD_kE_full, RMSD_kE_full_path, molColName='Molecule', idName='Pose ID')\n",
    "PandasTools.WriteSDF(spyRMSD_kE_full, spyRMSD_kE_full_path, molColName='Molecule', idName='Pose ID')\n",
    "PandasTools.WriteSDF(espsim_d_kE_full, espsim_d_kE_full_path, molColName='Molecule', idName='Pose ID')\n",
    "PandasTools.WriteSDF(mmff_kE_full, mmff_kE_full_path, molColName='Molecule', idName='Pose ID')\n",
    "PandasTools.WriteSDF(spyRMSD_mmff_kE_full, spyRMSD_mmff_kE_full_path, molColName='Molecule', idName='Pose ID')\n",
    "PandasTools.WriteSDF(RMSD_kS_full, RMSD_kS_full_path, molColName='Molecule', idName='Pose ID')\n",
    "PandasTools.WriteSDF(spyRMSD_kS_full, spyRMSD_kS_full_path, molColName='Molecule', idName='Pose ID')\n",
    "PandasTools.WriteSDF(espsim_d_kS_full, espsim_d_kS_full_path, molColName='Molecule', idName='Pose ID')\n",
    "PandasTools.WriteSDF(mmff_kS_full, mmff_kS_full_path, molColName='Molecule', idName='Pose ID')\n",
    "PandasTools.WriteSDF(spyRMSD_mmff_kS_full, spyRMSD_mmff_kS_full_path, molColName='Molecule', idName='Pose ID')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescoring_folder = root_dir+'/temp/rescoring'\n",
    "gnina_rescoring_folder = rescoring_folder+'/gnina_rescoring/'\n",
    "smina_rescoring_folder = rescoring_folder+'/smina_rescoring/'\n",
    "plp_rescoring_folder = rescoring_folder+'/plp_rescoring/'\n",
    "chemplp_rescoring_folder = rescoring_folder+'/chemplp_rescoring/'\n",
    "rfscore_rescoring_folder = rescoring_folder+'/rfscore_rescoring/'\n",
    "vinardo_rescoring_folder = rescoring_folder+'/vinardo_rescoring/'\n",
    "ecif_rescoring_folder = rescoring_folder+'/ecif_rescoring/'\n",
    "\n",
    "try:\n",
    "    os.mkdir(rescoring_folder)\n",
    "except:\n",
    "\tprint(\"Rescoring folder already exists\")\n",
    "try:\n",
    "    os.mkdir(gnina_rescoring_folder)\n",
    "except:\n",
    "\tprint(\"GNINA Rescoring folder already exist\")\n",
    "try:\n",
    "    os.mkdir(smina_rescoring_folder)\n",
    "except:\n",
    "\tprint(\"SMINA Rescoring folder already exists\")\n",
    "try:\n",
    "    os.mkdir(plp_rescoring_folder)\n",
    "except:\n",
    "\tprint(\"PLP Rescoring folder already exists\")\n",
    "try:\n",
    "    os.mkdir(chemplp_rescoring_folder)\n",
    "except:\n",
    "\tprint(\"CHEMPLP Rescoring folder already exists\")\n",
    "try:\n",
    "    os.mkdir(rfscore_rescoring_folder)\n",
    "except:\n",
    "\tprint(\"RFScore Rescoring folder already exists\")\n",
    "try:\n",
    "    os.mkdir(vinardo_rescoring_folder)\n",
    "except:\n",
    "\tprint(\"VINARDO Rescoring folder already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GNINA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnina_rescoring(sdf):\n",
    "\tcnn = 'crossdock_default2018'\n",
    "\tresults = gnina_rescoring_folder+'/rescored_'+cnn+'.sdf'\n",
    "\tlog_file = gnina_rescoring_folder+'log_'+cnn+'.txt'\n",
    "\n",
    "\tgnina_cmd = \"gnina -r \"+protein_file+\" -l \"+sdf+\" --autobox_ligand \"+ref_file+\" -o \"+results+\" --cnn \"+cnn+\" --log \"+log_file+\" --score_only\"\n",
    "\tdocker_cmd = \"sudo docker run --name gnina --rm -v /home:/home gnina/gnina \" + gnina_cmd \n",
    "\n",
    "\tsubprocess.call(docker_cmd, shell=True)\n",
    "\n",
    "\tlog = open(log_file, \"r\")\n",
    "\tlines = log.readlines()\n",
    "\tkeep = []\n",
    "\tfor l in lines:\n",
    "\t\tif l.startswith(\"##\") or l.startswith(\"Affinity\") or l.startswith(\"CNN\") or l.startswith(\"Intramolecular\"):\n",
    "\t\t\tkeep.append(l)\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\tfor k in keep:\n",
    "\t\tif k.startswith(\"## Name\"):\n",
    "\t\t\tkeep.remove(k)\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\tkeep = [keep[i:i+5] for i in range(0, len(keep), 5)]\n",
    "\tgnina_rescoring_results = pd.DataFrame()\n",
    "\tfor k in enumerate(keep):\n",
    "\t\ti = k[1]\n",
    "\t\tfor j in i:\n",
    "\t\t\tif j.startswith(\"##\"):\n",
    "\t\t\t\ta = j.split()\n",
    "\t\t\t\tgnina_rescoring_results.loc[k[0], 'Pose ID'] = a[1]\n",
    "\t\t\tif j.startswith(\"Affinity\"):\n",
    "\t\t\t\tb = j.split()\n",
    "\t\t\t\tgnina_rescoring_results.loc[k[0], 'Affinity_'+cnn] = b[1]\n",
    "\t\t\tif j.startswith(\"CNNscore\"):\n",
    "\t\t\t\tc = j.split()\n",
    "\t\t\t\tgnina_rescoring_results.loc[k[0], 'CNNscore_'+cnn] = c[1]\n",
    "\t\t\tif j.startswith(\"CNNaffinity\"):\n",
    "\t\t\t\td = j.split()\n",
    "\t\t\t\tgnina_rescoring_results.loc[k[0], 'CNNaffinity_'+cnn] = d[1]\n",
    "\t\t\tif j.startswith(\"Intramolecular\"):\n",
    "\t\t\t\te = j.split()\n",
    "\t\t\t\tgnina_rescoring_results.loc[k[0], 'Intramolecular'+cnn] = e[2]\n",
    "\t\t\telse:\n",
    "\t\t\t\tpass\n",
    "\treturn gnina_rescoring_results\n",
    "\n",
    "gnina_rescoring_results = gnina_rescoring('/home/tony/Documents/consensus_docking_python/temp/clustering/RMSD_kE_full.sdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMINA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smina_rescoring(sdf):\n",
    "\tresults = smina_rescoring_folder+'/rescored_.sdf'\n",
    "\tlog_file = smina_rescoring_folder+'log.txt'\n",
    "\n",
    "\tsmina_cmd = \"gnina -r \"+protein_file+\" -l \"+sdf+\" --autobox_ligand \"+ref_file+\" -o \"+results+\" --log \"+log_file+\" --score_only --cnn_scoring none\"\n",
    "\tdocker_cmd = \"sudo docker run --name gnina --rm -v /home:/home gnina/gnina \" + smina_cmd \n",
    "\n",
    "\tsubprocess.call(docker_cmd, shell=True)\n",
    "\n",
    "\tlog = open(log_file, \"r\")\n",
    "\tlines = log.readlines()\n",
    "\tkeep = []\n",
    "\tfor l in lines:\n",
    "\t\tif l.startswith(\"##\") or l.startswith(\"Affinity\") or l.startswith(\"CNN\") or l.startswith(\"Intramolecular\"):\n",
    "\t\t\tkeep.append(l)\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\n",
    "\tfor k in keep:\n",
    "\t\tif k.startswith(\"## Name\"):\n",
    "\t\t\tkeep.remove(k)\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\n",
    "\tkeep = [keep[i:i+5] for i in range(0, len(keep), 5)]\n",
    "\n",
    "\tsmina_rescoring_results = pd.DataFrame()\n",
    "\n",
    "\tfor k in enumerate(keep):\n",
    "\t\ti = k[1]\n",
    "\t\tfor j in i:\n",
    "\t\t\tif j.startswith(\"##\"):\n",
    "\t\t\t\ta = j.split()\n",
    "\t\t\t\tsmina_rescoring_results.loc[k[0], 'Pose ID'] = a[1]\n",
    "\t\t\tif j.startswith(\"Affinity\"):\n",
    "\t\t\t\tb = j.split()\n",
    "\t\t\t\tsmina_rescoring_results.loc[k[0], 'Affinity_smina'] = b[1]\n",
    "\t\t\tif j.startswith(\"CNNscore\"):\n",
    "\t\t\t\tc = j.split()\n",
    "\t\t\t\tsmina_rescoring_results.loc[k[0], 'CNNscore_smina'] = c[1]\n",
    "\t\t\tif j.startswith(\"CNNaffinity\"):\n",
    "\t\t\t\td = j.split()\n",
    "\t\t\t\tsmina_rescoring_results.loc[k[0], 'CNNaffinity_smina'] = d[1]\n",
    "\t\t\tif j.startswith(\"Intramolecular\"):\n",
    "\t\t\t\te = j.split()\n",
    "\t\t\t\tsmina_rescoring_results.loc[k[0], 'Intramolecular_smina'] = e[2]\n",
    "\t\t\telse:\n",
    "\t\t\t\tpass\n",
    "\treturn smina_rescoring_results\n",
    "\n",
    "smina_rescoring_results = smina_rescoring('/home/tony/Documents/consensus_docking_python/temp/clustering/RMSD_kE_full.sdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VINARDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vinardo_rescoring(sdf):\n",
    "\tresults = vinardo_rescoring_folder+'/rescored_.sdf'\n",
    "\tlog_file = vinardo_rescoring_folder+'log.txt'\n",
    "\n",
    "\tvinardo_cmd = \"gnina -r \"+protein_file+\" -l \"+sdf+\" --autobox_ligand \"+ref_file+\" -o \"+results+\" --log \"+log_file+\" --score_only --scoring vinardo --cnn_scoring none\"\n",
    "\tdocker_cmd = \"sudo docker run --name gnina --rm -v /home:/home gnina/gnina \" + vinardo_cmd \n",
    "\n",
    "\tsubprocess.call(docker_cmd, shell=True)\n",
    "\n",
    "\tlog = open(log_file, \"r\")\n",
    "\tlines = log.readlines()\n",
    "\tkeep = []\n",
    "\tfor l in lines:\n",
    "\t\tif l.startswith(\"##\") or l.startswith(\"Affinity\") or l.startswith(\"CNN\") or l.startswith(\"Intramolecular\"):\n",
    "\t\t\tkeep.append(l)\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\n",
    "\tfor k in keep:\n",
    "\t\tif k.startswith(\"## Name\"):\n",
    "\t\t\tkeep.remove(k)\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\n",
    "\tkeep = [keep[i:i+5] for i in range(0, len(keep), 5)]\n",
    "\n",
    "\tvinardo_rescoring_results = pd.DataFrame()\n",
    "\n",
    "\tfor k in enumerate(keep):\n",
    "\t\ti = k[1]\n",
    "\t\tfor j in i:\n",
    "\t\t\tif j.startswith(\"##\"):\n",
    "\t\t\t\ta = j.split()\n",
    "\t\t\t\tvinardo_rescoring_results.loc[k[0], 'Pose ID'] = a[1]\n",
    "\t\t\tif j.startswith(\"Affinity\"):\n",
    "\t\t\t\tb = j.split()\n",
    "\t\t\t\tvinardo_rescoring_results.loc[k[0], 'Affinity_vinardo'] = b[1]\n",
    "\t\t\tif j.startswith(\"CNNscore\"):\n",
    "\t\t\t\tc = j.split()\n",
    "\t\t\t\tvinardo_rescoring_results.loc[k[0], 'CNNscore_vinardo'] = c[1]\n",
    "\t\t\tif j.startswith(\"CNNaffinity\"):\n",
    "\t\t\t\td = j.split()\n",
    "\t\t\t\tvinardo_rescoring_results.loc[k[0], 'CNNaffinity_vinardo'] = d[1]\n",
    "\t\t\tif j.startswith(\"Intramolecular\"):\n",
    "\t\t\t\te = j.split()\n",
    "\t\t\t\tvinardo_rescoring_results.loc[k[0], 'Intramolecular_vinardo'] = e[2]\n",
    "\t\t\telse:\n",
    "\t\t\t\tpass\n",
    "\treturn vinardo_rescoring_results\n",
    "\n",
    "vinardo_rescoring_results = vinardo_rescoring('/home/tony/Documents/consensus_docking_python/temp/clustering/RMSD_kE_full.sdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plants_search_speed = \"speed1\"\n",
    "ants = \"20\"\n",
    "\n",
    "def plp_rescoring(sdf):\n",
    "    #Read protein and ref files generated during PLANTS docking\n",
    "    plants_protein_mol2 = root_dir+\"/temp/plants/protein.mol2\"\n",
    "    plants_ref_mol2 = root_dir+\"/temp/plants/ref.mol2\"\n",
    "    #Convert clustered ligand file to .mol2 using open babel\n",
    "    plants_ligands_mol2 = root_dir+\"/temp/plants/ligands.mol2\"\n",
    "    try:\n",
    "        obabel_command = 'obabel -isdf '+sdf+' -O '+plants_ligands_mol2\n",
    "        os.system(obabel_command)\n",
    "    except:\n",
    "        print('ERROR: Failed to convert clustered library file to .mol2!')\n",
    "    #Determine binding site coordinates\n",
    "    plants_binding_site_command = \"cd \"+software+\" && ./PLANTS --mode bind \"+plants_ref_mol2+\" 6\"\n",
    "    run_plants_binding_site = os.popen(plants_binding_site_command)\n",
    "    output_plants_binding_site = run_plants_binding_site.readlines()\n",
    "    keep = []\n",
    "    for l in output_plants_binding_site:\n",
    "        if l.startswith(\"binding\"):\n",
    "            keep.append(l)\n",
    "        else:\n",
    "            pass\n",
    "    binding_site_center = keep[0].split()\n",
    "    binding_site_radius = keep[1].split()\n",
    "    binding_site_radius = binding_site_radius[1]\n",
    "    binding_site_x = binding_site_center[1]\n",
    "    binding_site_y = binding_site_center[2]\n",
    "    binding_site_z = binding_site_center[3]\n",
    "    #Generate plants config file\n",
    "    plp_rescoring_config_path_txt = plp_rescoring_folder+\"config.txt\"\n",
    "    plp_config = ['# search algorithm\\n',\n",
    "    'search_speed '+plants_search_speed+'\\n',\n",
    "    'aco_ants '+ants+'\\n',\n",
    "    'flip_amide_bonds 0\\n',\n",
    "    'flip_planar_n 1\\n',\n",
    "    'force_flipped_bonds_planarity 0\\n',\n",
    "    'force_planar_bond_rotation 1\\n',\n",
    "    'rescore_mode simplex\\n',\n",
    "    'flip_ring_corners 0\\n',\n",
    "    '# scoring functions\\n',\n",
    "    '# Intermolecular (protein-ligand interaction scoring)\\n',\n",
    "    'scoring_function plp\\n',\n",
    "    'outside_binding_site_penalty 50.0\\n',\n",
    "    'enable_sulphur_acceptors 1\\n',\n",
    "    '# Intramolecular ligand scoring\\n',\n",
    "    'ligand_intra_score clash2\\n',\n",
    "    'chemplp_clash_include_14 1\\n',\n",
    "    'chemplp_clash_include_HH 0\\n',\n",
    "\n",
    "    '# input\\n',\n",
    "    'protein_file '+plants_protein_mol2+'\\n',\n",
    "    'ligand_file '+plants_ligands_mol2+'\\n',\n",
    "\n",
    "    '# output\\n',\n",
    "    'output_dir '+plp_rescoring_folder+'results\\n',\n",
    "\n",
    "    '# write single mol2 files (e.g. for RMSD calculation)\\n',\n",
    "    'write_multi_mol2 1\\n',\n",
    "\n",
    "    '# binding site definition\\n',\n",
    "    'bindingsite_center '+binding_site_x+' '+binding_site_y+' '+binding_site_z+'+\\n',\n",
    "    'bindingsite_radius '+binding_site_radius+'\\n',\n",
    "\n",
    "    '# cluster algorithm\\n',\n",
    "    'cluster_structures 10\\n',\n",
    "    'cluster_rmsd 2.0\\n',\n",
    "\n",
    "    '# write\\n',\n",
    "    'write_ranking_links 0\\n',\n",
    "    'write_protein_bindingsite 1\\n',\n",
    "    'write_protein_conformations 1\\n',\n",
    "    'write_protein_splitted 1\\n',\n",
    "    'write_merged_protein 0\\n',\n",
    "    '####\\n']\n",
    "    #Write config file\n",
    "    plp_rescoring_config_path_config = plp_rescoring_config_path_txt.replace(\".txt\", \".config\")\n",
    "    config = open(plp_rescoring_config_path_txt, 'w')\n",
    "    config.writelines(plp_config)\n",
    "    os.rename(plp_rescoring_config_path_txt, plp_rescoring_config_path_config)\n",
    "    #Run PLANTS docking\n",
    "    plp_rescoring_command = \"cd \"+software+\" && ./PLANTS --mode screen \"+plp_rescoring_config_path_config\n",
    "    os.system(plp_rescoring_command)\n",
    "    #Fetch results\n",
    "    results_csv_location = plp_rescoring_folder+'results/ranking.csv'\n",
    "    plp_results = pd.read_csv(results_csv_location, sep=',', header=0)\n",
    "    return plp_results\n",
    "\n",
    "plp_results = plp_rescoring('/home/tony/Documents/consensus_docking_python/temp/clustering/RMSD_kE_full.sdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHEMPLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plants_search_speed = \"speed1\"\n",
    "ants = \"20\"\n",
    "\n",
    "def chemplp_rescoring(sdf):\n",
    "    #Read protein and ref files generated during PLANTS docking\n",
    "    plants_protein_mol2 = root_dir+\"/temp/plants/protein.mol2\"\n",
    "    plants_ref_mol2 = root_dir+\"/temp/plants/ref.mol2\"\n",
    "    #Convert clustered ligand file to .mol2 using open babel\n",
    "    plants_ligands_mol2 = root_dir+\"/temp/plants/ligands.mol2\"\n",
    "    try:\n",
    "        obabel_command = 'obabel -isdf '+sdf+' -O '+plants_ligands_mol2\n",
    "        os.system(obabel_command)\n",
    "    except:\n",
    "        print('ERROR: Failed to convert clustered library file to .mol2!')\n",
    "    #Determine binding site coordinates\n",
    "    plants_binding_site_command = \"cd \"+software+\" && ./PLANTS --mode bind \"+plants_ref_mol2+\" 6\"\n",
    "    run_plants_binding_site = os.popen(plants_binding_site_command)\n",
    "    output_plants_binding_site = run_plants_binding_site.readlines()\n",
    "    keep = []\n",
    "    for l in output_plants_binding_site:\n",
    "        if l.startswith(\"binding\"):\n",
    "            keep.append(l)\n",
    "        else:\n",
    "            pass\n",
    "    binding_site_center = keep[0].split()\n",
    "    binding_site_radius = keep[1].split()\n",
    "    binding_site_radius = binding_site_radius[1]\n",
    "    binding_site_x = binding_site_center[1]\n",
    "    binding_site_y = binding_site_center[2]\n",
    "    binding_site_z = binding_site_center[3]\n",
    "    #Generate plants config file\n",
    "    chemplp_rescoring_config_path_txt = chemplp_rescoring_folder+\"config.txt\"\n",
    "    chemplp_config = ['# search algorithm\\n',\n",
    "    'search_speed '+plants_search_speed+'\\n',\n",
    "    'aco_ants '+ants+'\\n',\n",
    "    'flip_amide_bonds 0\\n',\n",
    "    'flip_planar_n 1\\n',\n",
    "    'force_flipped_bonds_planarity 0\\n',\n",
    "    'force_planar_bond_rotation 1\\n',\n",
    "    'rescore_mode simplex\\n',\n",
    "    'flip_ring_corners 0\\n',\n",
    "    '# scoring functions\\n',\n",
    "    '# Intermolecular (protein-ligand interaction scoring)\\n',\n",
    "    'scoring_function chemplp\\n',\n",
    "    'outside_binding_site_penalty 50.0\\n',\n",
    "    'enable_sulphur_acceptors 1\\n',\n",
    "    '# Intramolecular ligand scoring\\n',\n",
    "    'ligand_intra_score clash2\\n',\n",
    "    'chemplp_clash_include_14 1\\n',\n",
    "    'chemplp_clash_include_HH 0\\n',\n",
    "\n",
    "    '# input\\n',\n",
    "    'protein_file '+plants_protein_mol2+'\\n',\n",
    "    'ligand_file '+plants_ligands_mol2+'\\n',\n",
    "\n",
    "    '# output\\n',\n",
    "    'output_dir '+chemplp_rescoring_folder+'results\\n',\n",
    "\n",
    "    '# write single mol2 files (e.g. for RMSD calculation)\\n',\n",
    "    'write_multi_mol2 1\\n',\n",
    "\n",
    "    '# binding site definition\\n',\n",
    "    'bindingsite_center '+binding_site_x+' '+binding_site_y+' '+binding_site_z+'+\\n',\n",
    "    'bindingsite_radius '+binding_site_radius+'\\n',\n",
    "\n",
    "    '# cluster algorithm\\n',\n",
    "    'cluster_structures 10\\n',\n",
    "    'cluster_rmsd 2.0\\n',\n",
    "\n",
    "    '# write\\n',\n",
    "    'write_ranking_links 0\\n',\n",
    "    'write_protein_bindingsite 1\\n',\n",
    "    'write_protein_conformations 1\\n',\n",
    "    'write_protein_splitted 1\\n',\n",
    "    'write_merged_protein 0\\n',\n",
    "    '####\\n']\n",
    "    #Write config file\n",
    "    chemplp_rescoring_config_path_config = chemplp_rescoring_config_path_txt.replace(\".txt\", \".config\")\n",
    "    config = open(chemplp_rescoring_config_path_txt, 'w')\n",
    "    config.writelines(chemplp_config)\n",
    "    os.rename(chemplp_rescoring_config_path_txt, chemplp_rescoring_config_path_config)\n",
    "    #Run PLANTS docking\n",
    "    chemplp_rescoring_command = \"cd \"+software+\" && ./PLANTS --mode screen \"+chemplp_rescoring_config_path_config\n",
    "    os.system(chemplp_rescoring_command)\n",
    "    #Fetch results\n",
    "    results_csv_location = chemplp_rescoring_folder+'results/ranking.csv'\n",
    "    chemplp_results = pd.read_csv(results_csv_location, sep=',', header=0)\n",
    "    return chemplp_results\n",
    "\n",
    "chemplp_results = chemplp_rescoring('/home/tony/Documents/consensus_docking_python/temp/clustering/RMSD_kE_full.sdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFSCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfscore_rescoring(sdf):\n",
    "    results_path = rfscore_rescoring_folder+\"/ligands_rfscore.csv\"\n",
    "    cd = \"cd \"+software+\" &&\"\n",
    "    cmd = \"./rf-score-vs --receptor \"+protein_file+\" \"+sdf+\" -O \"+results_path+\" -o csv --field PoseID --field RFScoreVS_v2\"\n",
    "    rfscore_command = cd+cmd\n",
    "    os.system(rfscore_command)\n",
    "    rfscore_results = pd.read_csv(results_path, delimiter=',', header=0)\n",
    "    sdf_read = PandasTools.LoadSDF(sdf, idName='Pose ID', molColName='Molecule', includeFingerprints=False, removeHs=False)\n",
    "    id_list = list(sdf_read['Pose ID'])\n",
    "    rfscore_results['PoseID'] = id_list\n",
    "    return rfscore_results\n",
    "\n",
    "rfscore_rescoring_results = rfscore_rescoring('/home/tony/Documents/consensus_docking_python/temp/clustering/RMSD_kE_full.sdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3094ebdc4a88a261f63a4c61086277882d9c99ab72ea54c362959b6a0f6e3101"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('deepchem37': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
