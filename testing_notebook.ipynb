{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import required libraries and scripts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:46:17] Initializing Normalizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The working directory has been set to: /home/tony/CADD22/wocondock_performance_ace_test\n",
      "The folder: /home/tony/CADD22/wocondock_performance_ace_test/temp already exists\n"
     ]
    }
   ],
   "source": [
    "#Import required libraries and scripts\n",
    "from scripts.library_preparation import *\n",
    "from scripts.utilities import *\n",
    "from scripts.docking_functions import *\n",
    "from scripts.clustering_functions import *\n",
    "from scripts.rescoring_functions import *\n",
    "from scripts.ranking_functions import *\n",
    "from scripts.performance_calculation import *\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "software = '/home/tony/CADD22/software'\n",
    "protein_file = '/home/tony/CADD22/wocondock_performance_ace_test/receptor_protoss_prepared.pdb'\n",
    "ref_file = '/home/tony/CADD22/wocondock_performance_ace_test/crystal_ligand_protoss.sdf'\n",
    "docking_library = '/home/tony/CADD22/wocondock_performance_ace_test/merged_actives_decoys.sdf'\n",
    "docking_programs = ['GNINA', 'SMINA', 'PLANTS']\n",
    "clustering_metrics = ['RMSD', 'spyRMSD', 'espsim', 'USRCAT', '3DScore', 'bestpose', 'bestpose_GNINA', 'bestpose_SMINA', 'bestpose_PLANTS']\n",
    "rescoring_functions = ['gnina', 'AD4', 'chemplp', 'rfscorevs']\n",
    "id_column = 'ID'\n",
    "n_poses = 10\n",
    "exhaustiveness = 4\n",
    "\n",
    "#Initialise variables and create a temporary folder\n",
    "w_dir = os.path.dirname(protein_file)\n",
    "print('The working directory has been set to:', w_dir)\n",
    "create_temp_folder(w_dir+'/temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pocket_definition = binding_site_coordinates_dogsitescorer(protein_file, w_dir, method='volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_pkasolver_df = prepare_library(docking_library, id_column, software, 'pkasolver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_poses = docking(protein_file, ref_file, software, docking_programs, exhaustiveness, n_poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docking_splitted(w_dir, protein_file, ref_file, software, docking_programs, exhaustiveness, n_poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all poses SDF file...\n",
      "Finished loading all poses SDF in 1.4830!...\n"
     ]
    }
   ],
   "source": [
    "print('Loading all poses SDF file...')\n",
    "tic = time.perf_counter()\n",
    "all_poses = PandasTools.LoadSDF(w_dir+'/temp/allposes.sdf', idName='Pose ID', molColName='Molecule', includeFingerprints=False, strictParsing=True)\n",
    "toc = time.perf_counter()\n",
    "print(f'Finished loading all poses SDF in {toc-tic:0.4f}!...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.clustering_metrics import *\n",
    "from scripts.utilities import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "from rdkit.Chem import PandasTools\n",
    "from IPython.display import display\n",
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "def kmedoids_S_clustering(input_dataframe):\n",
    "    df = input_dataframe.copy()\n",
    "    molecule_list = input_dataframe.columns.values.tolist()\n",
    "    #preprocessing our data *scaling data* \n",
    "    scaler = StandardScaler()\n",
    "    df[molecule_list] = scaler.fit_transform(df)\n",
    "    silhouette_scores = {}\n",
    "    for num_clusters in range(2,5):\n",
    "        #calculating silhouette average score for every cluster and plotting them at the end\n",
    "        #choosing pam method as it's more accurate\n",
    "        # initialization of medoids is a greedy approach, as it's more effecient as well \n",
    "        kmedoids = KMedoids(n_clusters=num_clusters , method='pam',init='build' ,max_iter=150)\n",
    "        kmedoids.fit_predict(df)\n",
    "        silhouette_average_score = silhouette_score(df, kmedoids.labels_)\n",
    "        silhouette_scores[num_clusters] = silhouette_average_score\n",
    "    optimum_no_clusters = max(silhouette_scores, key=silhouette_scores.get)\n",
    "    # # Apply optimised k-medoids clustering\n",
    "    kmedoids = KMedoids(n_clusters=optimum_no_clusters, method='pam',init='build', max_iter=150)\n",
    "    clusters = kmedoids.fit_predict(df)\n",
    "    df['KMedoids Cluster'] = clusters\n",
    "    df['Pose ID'] = molecule_list\n",
    "    # Determine centers\n",
    "    centroids = kmedoids.cluster_centers_\n",
    "    cluster_centers = pd.DataFrame(centroids,columns = molecule_list)\n",
    "    #rearranging data\n",
    "    merged_df = pd.merge(df, cluster_centers, on=molecule_list, how='inner')\n",
    "    merged_df = merged_df[['Pose ID']]\n",
    "    #.astype(str).replace('[()\\',]','', regex=False)\n",
    "    return merged_df\n",
    "\n",
    "def affinity_propagation_clustering(input_dataframe):\n",
    "    df = input_dataframe.copy()\n",
    "    molecule_list = input_dataframe.columns.values.tolist()\n",
    "    #preprocessing our data *scaling data* \n",
    "    scaler = StandardScaler()\n",
    "    df[molecule_list] = scaler.fit_transform(df)\n",
    "    affinity_propagation = AffinityPropagation(max_iter=150)\n",
    "    clusters = affinity_propagation.fit_predict(df)\n",
    "    df['Affinity Cluster'] = clusters\n",
    "    df['Pose ID'] = molecule_list\n",
    "    # Determine centers\n",
    "    centroids = affinity_propagation.cluster_centers_\n",
    "    cluster_centers = pd.DataFrame(centroids,columns = molecule_list)\n",
    "    #rearranging data\n",
    "    merged_df = pd.merge(df, cluster_centers, on=molecule_list, how='inner')\n",
    "    merged_df = merged_df[['Pose ID']]\n",
    "    #.astype(str).replace('[()\\',]','', regex=False)\n",
    "    return merged_df\n",
    "\n",
    "def cluster(metric, method, w_dir, protein_file, all_poses):\n",
    "    create_temp_folder(w_dir+'/temp/clustering/')\n",
    "    def matrix_calculation_and_clustering(metric, method, df, id_list, protein_file): \n",
    "        clustered_dataframes = []\n",
    "        print(\"*Calculating {} metrics and clustering*\".format(metric))\n",
    "        metrics = {'RMSD': simpleRMSD_calc, 'spyRMSD': spyRMSD_calc, 'espsim': espsim_calc, 'USRCAT': USRCAT_calc, 'SPLIF': SPLIF_calc, '3DScore': '3DScore', 'bestpose': 'bestpose', 'symmRMSD': symmRMSD_calc}\n",
    "        methods = {'Kmedoids': kmedoids_S_clustering, 'AffProp': affinity_propagation_clustering}\n",
    "        for id in tqdm(id_list):\n",
    "            if metric == '3DScore':\n",
    "                df_filtered = df[df['ID']==id]\n",
    "                subsets = np.array(list(itertools.combinations(df_filtered['Molecule'], 2)))\n",
    "                indices = {mol: idx for idx, mol in enumerate(df_filtered['Molecule'].values)}\n",
    "                results = np.zeros(len(subsets))\n",
    "                for k, (x, y) in enumerate(subsets):\n",
    "                    try:\n",
    "                        results[k] = (metrics['spyRMSD'](x, y, protein_file))\n",
    "                    except:\n",
    "                        results[k] = (metrics['RMSD'](x, y, protein_file))\n",
    "                i, j = np.array([indices[x] for x in subsets[:,0]]), np.array([indices[y] for y in subsets[:,1]])\n",
    "                matrix = np.zeros((len(df_filtered), len(df_filtered)))\n",
    "                matrix[i, j] = results\n",
    "                matrix[j, i] = results\n",
    "                matrix_df = pd.DataFrame(matrix, index=df_filtered['Pose ID'].values.tolist(), columns=df_filtered['Pose ID'].values.tolist())\n",
    "                matrix_df['3DScore'] = matrix_df.sum(axis=1)\n",
    "                matrix_df.sort_values(by='3DScore', ascending=True, inplace=True)\n",
    "                matrix_df = matrix_df.head(1)\n",
    "                matrix_df = pd.DataFrame(matrix_df.index, columns=['Pose ID'])\n",
    "                matrix_df['Pose ID'] = matrix_df['Pose ID'].astype(str).str.replace('[()\\',]','', regex=False)\n",
    "                clustered_dataframes.append(matrix_df)\n",
    "            else:\n",
    "                #try:\n",
    "                    df_filtered = df[df['ID']==id]\n",
    "                    subsets = np.array(list(itertools.combinations(df_filtered['Molecule'].unique(), 2)))\n",
    "                    indices = {mol: idx for idx, mol in enumerate(df_filtered['Molecule'].values)}\n",
    "                    results = np.array([metrics[metric](x, y, protein_file) for x, y in subsets])\n",
    "                    i = np.array([indices[x] for x in subsets[:,0]])\n",
    "                    j = np.array([indices[y] for y in subsets[:,1]])\n",
    "                    matrix = np.zeros((len(df_filtered), len(df_filtered)))\n",
    "                    matrix[i, j] = results\n",
    "                    matrix[j, i] = results\n",
    "                    matrix_df = pd.DataFrame(matrix, index=df_filtered['Pose ID'].values.tolist(), columns=df_filtered['Pose ID'].values.tolist())\n",
    "                    clust_df = methods[method](matrix_df)\n",
    "                    clustered_dataframes.append(clust_df)\n",
    "                #except Exception as e:\n",
    "                    #print(f'Failed to calculate metrics and cluster ID: {id} due to : {e}')\n",
    "        clustered_poses = pd.concat(clustered_dataframes)\n",
    "        clustered_poses['Pose ID'] = clustered_poses['Pose ID'].astype(str).replace('[()\\',]','', regex=True)\n",
    "        return clustered_poses\n",
    "    if os.path.isfile(w_dir + '/temp/clustering/' + metric + '_clustered.sdf') == False:\n",
    "        id_list = np.unique(np.array(all_poses['ID']))\n",
    "        best_pose_filters = {'bestpose': ('_1', '_01'),\n",
    "                            'bestpose_GNINA': ('GNINA_1','GNINA_01'),\n",
    "                            'bestpose_SMINA': ('SMINA_1','SMINA_01'),\n",
    "                            'bestpose_PLANTS': ('PLANTS_1','PLANTS_01')}\n",
    "        if metric in best_pose_filters:\n",
    "            filter = best_pose_filters[metric]\n",
    "            clustered_poses = all_poses[all_poses['Pose ID'].str.endswith(filter)]\n",
    "            clustered_poses = clustered_poses[['Pose ID']]\n",
    "            clustered_poses['Pose ID'] = clustered_poses['Pose ID'].astype(str).str.replace('[()\\',]','', regex=False)\n",
    "        else:\n",
    "            clustered_poses = matrix_calculation_and_clustering(metric, method, all_poses, id_list, protein_file)\n",
    "        clustered_poses = pd.merge(all_poses, clustered_poses, on='Pose ID')\n",
    "        clustered_poses = clustered_poses[['Pose ID', 'Molecule', 'ID']]\n",
    "        save_path = w_dir + '/temp/clustering/' + metric + '_clustered.sdf'\n",
    "        PandasTools.WriteSDF(clustered_poses, save_path, molColName='Molecule', idName='Pose ID')\n",
    "    else:\n",
    "        print(f'Clustering using {metric} already done, moving to next metric...')\n",
    "    return\n",
    "\n",
    "def metric_calculation_failure_handling(x, y, metric, protein_file):\n",
    "    metrics = {'RMSD': simpleRMSD_calc, 'spyRMSD': spyRMSD_calc, 'espsim': espsim_calc, 'USRCAT': USRCAT_calc, 'SPLIF': SPLIF_calc, '3DScore': '3DScore', 'bestpose': 'bestpose', 'symmRMSD': symmRMSD_calc}\n",
    "    if metric == 'spyRMSD':\n",
    "        try:\n",
    "            return metrics[metric](x, y, protein_file)\n",
    "        except Exception as e:\n",
    "            return metrics['RMSD'](x, y, protein_file)\n",
    "    else:\n",
    "        try:\n",
    "            return metrics[metric](x, y, protein_file)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to calculate {metric} and cluster : {e}')\n",
    "            return 0\n",
    "\n",
    "def matrix_calculation_and_clustering_futures_failure_handling(metric, method, df, protein_file):\n",
    "    methods = {'Kmedoids': kmedoids_S_clustering, 'AffProp': affinity_propagation_clustering}\n",
    "    if metric == '3DScore':\n",
    "        subsets = np.array(list(itertools.combinations(df['Molecule'], 2)))\n",
    "        indices = {mol: idx for idx, mol in enumerate(df['Molecule'].values)}\n",
    "        vectorized_calc_vec = np.vectorize(metric_calculation_failure_handling)\n",
    "        results = vectorized_calc_vec(subsets[:,0], subsets[:,1], 'spyRMSD', protein_file)\n",
    "        i, j = np.array([indices[x] for x in subsets[:,0]]), np.array([indices[y] for y in subsets[:,1]])\n",
    "        matrix = np.zeros((len(df), len(df)))\n",
    "        matrix[i, j] = results\n",
    "        matrix[j, i] = results\n",
    "        output_df = pd.DataFrame(matrix, index=df['Pose ID'].values.tolist(), columns=df['Pose ID'].values.tolist())\n",
    "        output_df['3DScore'] = output_df.sum(axis=1)\n",
    "        output_df.sort_values(by='3DScore', ascending=True, inplace=True)\n",
    "        output_df = output_df.head(1)\n",
    "        output_df = pd.DataFrame(output_df.index, columns=['Pose ID'])\n",
    "        output_df['Pose ID'] = output_df['Pose ID'].astype(str).str.replace('[()\\',]','', regex=False)\n",
    "        return output_df\n",
    "    else:\n",
    "        subsets = np.array(list(itertools.combinations(df['Molecule'], 2)))\n",
    "        indices = {mol: idx for idx, mol in enumerate(df['Molecule'].values)}\n",
    "        vectorized_calc_vec = np.vectorize(metric_calculation_failure_handling)\n",
    "        results = vectorized_calc_vec(subsets[:,0], subsets[:,1], metric, protein_file)\n",
    "        i, j = np.array([indices[x] for x in subsets[:,0]]), np.array([indices[y] for y in subsets[:,1]])\n",
    "        matrix = np.zeros((len(df), len(df)))\n",
    "        matrix[i, j] = results\n",
    "        matrix[j, i] = results\n",
    "        matrix_df = pd.DataFrame(matrix, index=df['Pose ID'].values.tolist(), columns=df['Pose ID'].values.tolist())\n",
    "        matrix_df.fillna(0)\n",
    "        clust_df = methods[method](matrix_df)\n",
    "        return clust_df\n",
    "\n",
    "def cluster_futures(metric, method, w_dir, protein_file, all_poses):\n",
    "    create_temp_folder(w_dir+'/temp/clustering/')\n",
    "    if os.path.isfile(w_dir + '/temp/clustering/' + metric + '_clustered.sdf') == False:\n",
    "        id_list = np.unique(np.array(all_poses['ID']))\n",
    "        print(f\"*Calculating {metric} metrics and clustering*\")\n",
    "        best_pose_filters = {'bestpose': ('_1', '_01'),\n",
    "                            'bestpose_GNINA': ('GNINA_1',),\n",
    "                            'bestpose_SMINA': ('SMINA_1',),\n",
    "                            'bestpose_PLANTS': ('PLANTS_01',)}\n",
    "        if metric in best_pose_filters:\n",
    "            filter = best_pose_filters[metric]\n",
    "            clustered_poses = all_poses[all_poses['Pose ID'].str.endswith(filter)]\n",
    "            clustered_poses = clustered_poses[['Pose ID']]\n",
    "            clustered_poses['Pose ID'] = clustered_poses['Pose ID'].astype(str).str.replace('[()\\',]','', regex=False)\n",
    "        else:\n",
    "            clustered_dataframes = []\n",
    "            with concurrent.futures.ProcessPoolExecutor(max_workers=int(multiprocessing.cpu_count()/2)) as executor:\n",
    "                print('Submitting parallel jobs...')\n",
    "                tic = time.perf_counter()\n",
    "                jobs = []\n",
    "                for current_id in tqdm(id_list):\n",
    "                    try:\n",
    "                        job = executor.submit(matrix_calculation_and_clustering_futures_failure_handling, metric, method, all_poses[all_poses['ID']==current_id], protein_file)\n",
    "                        jobs.append(job)\n",
    "                    except Exception as e:\n",
    "                        print(\"Error in concurrent futures job creation: \", str(e))\t\n",
    "                toc = time.perf_counter()\n",
    "                print(f'Finished submitting jobs in {toc-tic:0.4f}, now running jobs...')\n",
    "                for job in tqdm(concurrent.futures.as_completed(jobs), total=len(id_list)):\n",
    "                    try:\n",
    "                        res = job.result()\n",
    "                        clustered_dataframes.append(res)\n",
    "                    except Exception as e:\n",
    "                        print(\"Error in concurrent futures job run: \", str(e))\n",
    "            clustered_poses = pd.concat(clustered_dataframes)\n",
    "        clustered_poses['Pose ID'] = clustered_poses['Pose ID'].astype(str).replace('[()\\',]','', regex=True)\n",
    "        clustered_poses = pd.merge(all_poses, clustered_poses, on='Pose ID')\n",
    "        clustered_poses = clustered_poses[['Pose ID', 'Molecule', 'ID']]\n",
    "        save_path = w_dir + '/temp/clustering/' + metric + '_clustered.sdf'\n",
    "        PandasTools.WriteSDF(clustered_poses, save_path, molColName='Molecule', idName='Pose ID')\n",
    "    else:\n",
    "        print(f'Clustering using {metric} already done, moving to next metric...')\n",
    "    return\n",
    "\n",
    "def cluster_mp(metric, method, w_dir, protein_file, all_poses):\n",
    "    create_temp_folder(w_dir+'/temp/clustering/')\n",
    "    if os.path.isfile(w_dir + '/temp/clustering/' + metric + '_clustered.sdf') == False:\n",
    "        id_list = np.unique(np.array(all_poses['ID']))\n",
    "        print(f\"*Calculating {metric} metrics and clustering*\")\n",
    "        best_pose_filters = {'bestpose': ('_1', '_01'),\n",
    "                            'bestpose_GNINA': ('GNINA_1',),\n",
    "                            'bestpose_SMINA': ('SMINA_1',),\n",
    "                            'bestpose_PLANTS': ('PLANTS_01',)}\n",
    "        if metric in best_pose_filters:\n",
    "            filter = best_pose_filters[metric]\n",
    "            clustered_poses = all_poses[all_poses['Pose ID'].str.endswith(filter)]\n",
    "            clustered_poses = clustered_poses[['Pose ID']]\n",
    "            clustered_poses['Pose ID'] = clustered_poses['Pose ID'].astype(str).str.replace('[()\\',]','', regex=False)\n",
    "        else:\n",
    "            clustered_dataframes = []\n",
    "            with multiprocessing.Pool(processes=int(multiprocessing.cpu_count()/2)) as pool:\n",
    "                print('Running parallel jobs...')\n",
    "                tic = time.perf_counter()\n",
    "                results = [pool.apply_async(matrix_calculation_and_clustering_futures_failure_handling, (metric, method, all_poses[all_poses['ID']==current_id], protein_file)) for current_id in id_list]\n",
    "                toc = time.perf_counter()\n",
    "                print(f'Finished running jobs in {toc-tic:0.4f}, now processing results...')\n",
    "                for res in tqdm(results, total=len(id_list)):\n",
    "                    clustered_dataframes.append(res.get())\n",
    "            clustered_poses = pd.concat(clustered_dataframes)\n",
    "        clustered_poses['Pose ID'] = clustered_poses['Pose ID'].astype(str).replace('[()\\',]','', regex=True)\n",
    "        clustered_poses = pd.merge(all_poses, clustered_poses, on='Pose ID')\n",
    "        clustered_poses = clustered_poses[['Pose ID', 'Molecule', 'ID']]\n",
    "        save_path = w_dir + '/temp/clustering/' + metric + '_clustered.sdf'\n",
    "        PandasTools.WriteSDF(clustered_poses, save_path, molColName='Molecule', idName='Pose ID')\n",
    "    else:\n",
    "        print(f'Clustering using {metric} already done, moving to next metric...')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder: /home/tony/CADD22/wocondock_performance_ace_test/temp/clustering/ was created\n",
      "*Calculating RMSD metrics and clustering*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [00:12<00:00, 15.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder: /home/tony/CADD22/wocondock_performance_ace_test/temp/clustering/ already exists\n",
      "*Calculating spyRMSD metrics and clustering*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [01:28<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder: /home/tony/CADD22/wocondock_performance_ace_test/temp/clustering/ already exists\n",
      "*Calculating espsim metrics and clustering*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [00:08<00:00, 22.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder: /home/tony/CADD22/wocondock_performance_ace_test/temp/clustering/ already exists\n",
      "*Calculating USRCAT metrics and clustering*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 13/198 [00:15<03:48,  1.24s/it]"
     ]
    }
   ],
   "source": [
    "for metric in clustering_metrics:\n",
    "    cluster(f'{metric}', 'KMedoids', w_dir, protein_file, all_poses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rescoring**\n",
    "\n",
    "The file containing all the cluster centers is then rescored using all scoring functions available (GNINA, Vina, AutoDock4, PLP, CHEMPLP, RF-Score-VS). The rescored output is return as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['bestpose', 'bestpose_GNINA', 'bestpose_SMINA', 'bestpose_PLANTS']:\n",
    "    rescore_all(w_dir, protein_file, ref_file, software, w_dir+f'/temp/clustering/{metric}_clustered.sdf', rescoring_functions, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final ranking methods**\n",
    "\n",
    "This code calculates the final ranking of compounds using various methods.\n",
    "*Method 1* : Calculates ECR value for each cluster center, then outputs the top ranked center.\n",
    "*Method 2* : Calculates ECR value for each cluster center, then outputs the average ECR value for each compound.\n",
    "*Method 3* : Calculates the average rank of each compound, then ouputs the corresponding ECR value for each compound.\n",
    "*Method 6* : Calculates Z-score for each cluster center, then ouputs the top ranked center.\n",
    "*Method 7* : Calculates Z-score for each cluster center, then ouputs the average Z-score for each compound.\n",
    "\n",
    "All methods are then combined into a single dataframe for comparison purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_consensus_methods(w_dir, ['bestpose_GNINA', 'bestpose_SMINA', 'bestpose_PLANTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_EFs(w_dir, docking_library)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('wocondock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac9acbc93af693fb4e01b586b9d883cf48eab2850c268069ebbf85c5f9fbe2b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
