{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import required libraries and scripts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:55:34] Initializing Normalizer\n"
     ]
    }
   ],
   "source": [
    "#Import required libraries and scripts\n",
    "from scripts.library_preparation import *\n",
    "from scripts.utilities import *\n",
    "from scripts.docking_functions import *\n",
    "from scripts.clustering_functions import *\n",
    "from scripts.rescoring_functions import *\n",
    "from scripts.ranking_functions import *\n",
    "from scripts.performance_calculation import *\n",
    "from scripts.dogsitescorer import *\n",
    "from scripts.get_pocket import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up**\n",
    "- **software**: The path to the software folder.\n",
    "- **proteinfile**: The path to the protein file (.pdb).\n",
    "- **pocket**: The method to use for pocket determination. Must be one of 'reference' or 'dogsitescorer'.\n",
    "- **dockinglibrary: The path to the docking library file (.sdf).\n",
    "- **idcolumn**: The unique identifier column used in the docking library.\n",
    "- **protonation**: The method to use for compound protonation. Must be one of 'pkasolver', 'GypsumDL', or 'None'.\n",
    "- **docking**: The method(s) to use for docking. Must be one or more of 'GNINA', 'SMINA', or 'PLANTS'.\n",
    "- **metric**: The method(s) to use for pose clustering. Must be one or more of 'RMSD', 'spyRMSD', 'espsim', 'USRCAT', '3DScore', 'bestpose', 'bestpose_GNINA', 'bestpose_SMINA', or 'bestpose_PLANTS'.\n",
    "- **nposes**: The number of poses to generate for each docking software. Default=10\n",
    "- **exhaustiveness**: The precision used if docking with SMINA/GNINA. Default=8\n",
    "- **parallel**: Whether or not to run the workflow in parallel. Default=1 (on). Can be set to 1 (on) or 0 (off).\n",
    "- **ncpus**: The number of cpus to use for the workflow. Default behavior is to use half of the available cpus.\n",
    "- **clustering**: Which algorithm to use for clustering. Must be one of 'KMedoids', 'Aff_prop'.\n",
    "- **rescoring**: Which scoring functions to use for rescoring. Must be one or more of 'gnina', 'AD4', 'chemplp', 'rfscorevs', 'LinF9', 'vinardo', 'plp', 'AAScore'.\n",
    "\n",
    "The software will then create a temporary directory to store the output of the various functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The working directory has been set to: ./wocondock_main\n",
      "The folder: ./wocondock_main/temp already exists\n"
     ]
    }
   ],
   "source": [
    "software = '/home/tony/DockM8/software'\n",
    "protein_file = '/home/tony/DockM8/wocondock_main/2o1x_A_apo_protoss.pdb'\n",
    "ref_file = '/home/tony/DockM8/wocondock_main/2o1x_A_lig_protoss.sdf'\n",
    "pocket = 'reference'\n",
    "protonation = 'pkasolver'\n",
    "docking_library = './wocondock_main/Selection_of_FCHGroup_LeadLike.sdf'\n",
    "docking_programs = ['GNINA', 'SMINA', 'PLANTS']\n",
    "clustering_metrics = ['RMSD']\n",
    "clustering_method = 'KMedoids'\n",
    "rescoring= ['SCORCH']\n",
    "id_column = 'ID'\n",
    "n_poses = 10\n",
    "exhaustiveness = 8\n",
    "parallel = 1\n",
    "ncpus = int(os.cpu_count()/2)\n",
    "#Create a temporary folder for all further calculations\n",
    "w_dir = os.path.dirname(protein_file)\n",
    "print('The working directory has been set to:', w_dir)\n",
    "create_temp_folder(w_dir+'/temp')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pocket Extraction**  \n",
    "\n",
    "This cell will extract the pocket based on the method specified in the 'pocket' variable. Using 'reference' will use the reference ligand to define the pocket. Using 'dogsitescore' will query the dogsitescorer server and use the pocket with the largest volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(protein_file.replace('.pdb', '_pocket.pdb')) == False:\n",
    "    if pocket == 'reference':\n",
    "        pocket_definition = GetPocket(ref_file, protein_file, 8)\n",
    "    elif pocket == 'dogsitescorer':\n",
    "        pocket_definition = binding_site_coordinates_dogsitescorer(protein_file, w_dir, method='volume')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Library preparation**\n",
    "\n",
    "This function will first standardize the library using the ChemBL structure pipeline. This will remove salts and make the library consistent.\n",
    "\n",
    "Protonation states can be calculated by one of three methods depending on the value of the 'protonation' variable:\n",
    "- pkasolver : will use the pkasolver library to predict a single protonation state\n",
    "- GypsumDL : will use the GypsumDL program to predict a single protonation state\n",
    "- None : will skip protonation and use the protonation state supplied in the docking library\n",
    "\n",
    "Finally, one 3D conformer is generated per molecule using GypsumDL.\n",
    "\n",
    "The final_library is then written to a file in the main directory (final_library.sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(w_dir+'/temp/final_library.sdf') == False:\n",
    "    prepare_library(docking_library, id_column, software, protonation, ncpus)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Docking**\n",
    "\n",
    "This cell will dock all compounds in the receptor, using the reference ligand as a way to define the binding site. (Note: DogSiteScorer not yet implemented here).\n",
    "\n",
    "The docking algorithms specified in the 'docking' variable will be used.\n",
    "\n",
    "The docking will be done in on parallel CPU cores depending on the value or the 'parallel' variable.\n",
    "\n",
    "The docking results are written to the temporary folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docking_programs = {'GNINA': w_dir+'/temp/gnina/', 'SMINA': w_dir+'/temp/smina/', 'PLANTS': w_dir+'/temp/plants/'}\n",
    "if parallel == 1:\n",
    "    for program, file_path in docking_programs.items():\n",
    "        if os.path.isdir(file_path) == False and program in docking_programs:\n",
    "            docking_splitted(w_dir, protein_file, ref_file, software, [program], exhaustiveness, n_poses, ncpus)\n",
    "else:\n",
    "    for program, file_path in docking_programs.items():\n",
    "        if os.path.isdir(file_path) == False and program in docking_programs:\n",
    "            docking(w_dir, protein_file, ref_file, software, [program], exhaustiveness, n_poses, ncpus)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combining docking poses**\n",
    "\n",
    "This cell combine all the poses from the docking programs in a single .sdf file. Depending on the value of the 'parallel' variable, this is done slightly differently due to the splitting of the library if 'parallel' is set to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if parallel == 1:\n",
    "    if os.path.isfile(w_dir+'/temp/allposes.sdf') == False:\n",
    "        fetch_poses_splitted(w_dir, n_poses, w_dir+'/temp/split_final_library')\n",
    "else:\n",
    "    if os.path.isfile(w_dir+'/temp/allposes.sdf') == False:\n",
    "        fetch_poses(w_dir, n_poses, w_dir+'/temp/split_final_library')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All poses are then loaded into memory for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading all poses SDF file...')\n",
    "tic = time.perf_counter()\n",
    "all_poses = PandasTools.LoadSDF(w_dir+'/temp/allposes.sdf', idName='Pose ID', molColName='Molecule', includeFingerprints=False, strictParsing=True)\n",
    "toc = time.perf_counter()\n",
    "print(f'Finished loading all poses SDF in {toc-tic:0.4f}!...')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering**\n",
    "\n",
    "This cell will perform the clustering according to the values of the 'clusering_metrics', 'clustering_method' and 'parallel' variables. If it detects that the clustering file for that metric has already been generated, it will skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if parallel == 1:\n",
    "    for metric in clustering_metrics:\n",
    "        if os.path.isfile(w_dir+f'/temp/clustering/{metric}_clustered.sdf') == False:\n",
    "            cluster_futures(metric, clustering_method, w_dir, protein_file, all_poses, ncpus)\n",
    "else:\n",
    "    for metric in clustering_metrics:\n",
    "        if os.path.isfile(w_dir+f'/temp/clustering/{metric}_clustered.sdf') == False:\n",
    "            cluster(metric, clustering_method, w_dir, protein_file, all_poses, ncpus)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rescoring**\n",
    "\n",
    "This cell will rescore all the clustered .sdf files according to the specified scoring functions and the value of the 'parallel' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder: ./wocondock_main/temp/rescoring_RMSD_clustered already exists\n",
      "The folder: ./wocondock_main/temp/rescoring_RMSD_clustered/SCORCH_rescoring/ was created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "*** Open Babel Warning  in PerceiveBondOrders\n",
      "  Failed to kekulize aromatic bonds in OBMol::PerceiveBondOrders (title is ./wocondock_main/2o1x_A_apo_protoss.pdb)\n",
      "\n",
      "1 molecule converted\n",
      "28 molecules converted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2023-Mar-20 19:59:40]: python ./software/SCORCH-main/scorch.py --receptor ./wocondock_main/temp/rescoring_RMSD_clustered/SCORCH_rescoring/protein.pdbqt --ligand ./wocondock_main/temp/rescoring_RMSD_clustered/SCORCH_rescoring/ligands.pdbqt --out ./wocondock_main/temp/rescoring_RMSD_clustered/SCORCH_rescoring/scoring_results.csv --threads 8 --verbose --return_pose_scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tony/.conda/envs/wocondock/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "\n",
      "\n",
      "**************************************************************************\n",
      "SCORCH v1.0\n",
      "Miles McGibbon, Samuel Money-Kyrle, Vincent Blay & Douglas R. Houston\n",
      "\n",
      "**************************************************************************\n",
      "\n",
      "Found 1 ligand(s) for scoring against a single receptor...\n",
      "\n",
      "**************************************************************************\n",
      "\n",
      "Counting input poses...\n",
      "100%|██████████| 1/1 [00:00<00:00, 738.04it/s]\n",
      "\n",
      "**************************************************************************\n",
      "\n",
      "Model Request Summary:\n",
      "\n",
      "XGBoost Model: Yes\n",
      "Traceback (most recent call last):\n",
      "  File \"./software/SCORCH-main/scorch.py\", line 1265, in <module>\n",
      "    scoring_function_results = scoring(params)\n",
      "  File \"./software/SCORCH-main/scorch.py\", line 1219, in scoring\n",
      "    model_dict = prepare_models(params)\n",
      "  File \"./software/SCORCH-main/scorch.py\", line 1054, in prepare_models\n",
      "    models['xgboost_model'] = pickle.load(open(xgb_path,'rb'))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'utils/models/xgboost_models/495_models_58_booster.pkl'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2023-Mar-20 19:59:46]: Rescoring with SCORCH complete in 94.2967!\n",
      "\n",
      "[2023-Mar-20 19:59:46]: Combining all score for ./wocondock_main/temp/rescoring_RMSD_clustered\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m clustering_metrics:\n\u001b[0;32m----> 2\u001b[0m         rescore_all(w_dir, protein_file, ref_file, software, w_dir\u001b[39m+\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/temp/clustering/\u001b[39;49m\u001b[39m{\u001b[39;49;00mmetric\u001b[39m}\u001b[39;49;00m\u001b[39m_clustered.sdf\u001b[39;49m\u001b[39m'\u001b[39;49m, rescoring, parallel, ncpus)\n",
      "File \u001b[0;32m~/DockM8/scripts/rescoring_functions.py:607\u001b[0m, in \u001b[0;36mrescore_all\u001b[0;34m(w_dir, protein_file, ref_file, software, clustered_sdf, functions, mp, ncpus)\u001b[0m\n\u001b[1;32m    605\u001b[0m csv_files \u001b[39m=\u001b[39m [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(subdir, file) \u001b[39mfor\u001b[39;00m subdir, dirs, files \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mwalk(rescoring_folder) \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m files \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m score_files]\n\u001b[1;32m    606\u001b[0m csv_dfs \u001b[39m=\u001b[39m [pd\u001b[39m.\u001b[39mread_csv(f, index_col\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m csv_files]\n\u001b[0;32m--> 607\u001b[0m combined_dfs \u001b[39m=\u001b[39m csv_dfs[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m    608\u001b[0m \u001b[39mfor\u001b[39;00m df \u001b[39min\u001b[39;00m tqdm(csv_dfs[\u001b[39m1\u001b[39m:], desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCombining scores\u001b[39m\u001b[39m'\u001b[39m, unit\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfiles\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    609\u001b[0m     combined_dfs \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(combined_dfs, df, left_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPose ID\u001b[39m\u001b[39m'\u001b[39m, right_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPose ID\u001b[39m\u001b[39m'\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minner\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for metric in clustering_metrics:\n",
    "        rescore_all(w_dir, protein_file, ref_file, software, w_dir+f'/temp/clustering/{metric}_clustered.sdf', rescoring, parallel, ncpus)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final ranking methods**\n",
    "\n",
    "This code calculates the final ranking of compounds using various methods.\n",
    "- *Method 1* : Calculates ECR value for each cluster center, then outputs the top ranked center.\n",
    "- *Method 2* : Calculates ECR value for each cluster center, then outputs the average ECR value for each compound.\n",
    "- *Method 3* : Calculates the average rank of each compound, then ouputs the corresponding ECR value for each compound.\n",
    "- *Method 4* : Calculates the Rank by Rank consensus\n",
    "- *Method 5* : Calculates the Rank by Vote consensus\n",
    "- *Method 6* : Calculates Z-score for each cluster center, then ouputs the top ranked center.\n",
    "- *Method 7* : Calculates Z-score for each cluster center, then ouputs the average Z-score for each compound.\n",
    "\n",
    "All methods are then combined into a single dataframe for comparison purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_consensus_methods(w_dir, clustering_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('wocondock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac9acbc93af693fb4e01b586b9d883cf48eab2850c268069ebbf85c5f9fbe2b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
